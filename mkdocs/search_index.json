{
    "docs": [
        {
            "location": "/", 
            "text": "Tr\u00e6fik (pronounced like \ntraffic\n) is a modern HTTP reverse proxy and load balancer made to deploy microservices with ease.\nIt supports several backends (\nDocker\n, \nSwarm mode\n, \nKubernetes\n, \nMarathon\n, \nConsul\n, \nEtcd\n, \nRancher\n, \nAmazon ECS\n, and a lot more) to manage its configuration automatically and dynamically.\n\n\nOverview\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\nBut a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.\n\n\nTraditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.\n\n\nHere enters Tr\u00e6fik.\n\n\n\n\nTr\u00e6fik can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.\n\n\nRun it and forget it!\n\n\nFeatures\n\n\n\n\nIt's fast\n\n\nNo dependency hell, single binary made with go\n\n\nTiny\n \nofficial\n official docker image\n\n\nRest API\n\n\nHot-reloading of configuration. No need to restart the process\n\n\nCircuit breakers, retry\n\n\nRound Robin, rebalancer load-balancers\n\n\nMetrics (Rest, Prometheus, Datadog, Statd)\n\n\nClean AngularJS Web UI\n\n\nWebsocket, HTTP/2, GRPC ready\n\n\nAccess Logs (JSON, CLF)\n\n\nLet's Encrypt\n support (Automatic HTTPS with renewal)\n\n\nHigh Availability with cluster mode\n\n\n\n\nSupported backends\n\n\n\n\nDocker\n / \nSwarm mode\n\n\nKubernetes\n\n\nMesos\n / \nMarathon\n\n\nRancher\n (API, Metadata)\n\n\nConsul\n / \nEtcd\n / \nZookeeper\n / \nBoltDB\n\n\nEureka\n\n\nAmazon ECS\n\n\nAmazon DynamoDB\n\n\nFile\n\n\nRest API\n\n\n\n\nQuickstart\n\n\nYou can have a quick look at Tr\u00e6fik in this \nKatacoda tutorial\n that shows how to load balance requests between multiple Docker containers.\n\n\nHere is a talk given by \nEmile Vauge\n at \nGopherCon 2017\n.\nYou will learn Tr\u00e6fik basics in less than 10 minutes. \n\n\n\n\nHere is a talk given by \nEd Robinson\n at \nContainerCamp UK\n conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.\n\n\n\n\nGet it\n\n\nBinary\n\n\nYou can grab the latest binary from the \nreleases\n page and just run it with the \nsample configuration file\n:\n\n\n./traefik -c traefik.toml\n\n\n\n\nDocker\n\n\nUsing the tiny Docker image:\n\n\ndocker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik\n\n\n\n\nTest it\n\n\nYou can test Tr\u00e6fik easily using \nDocker compose\n, with this \ndocker-compose.yml\n file in a folder named \ntraefik\n:\n\n\nversion: '2'\n\nservices:\n  proxy:\n    image: traefik\n    command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n    networks:\n      - webgateway\n    ports:\n      - \n80:80\n\n      - \n8080:8080\n\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /dev/null:/traefik.toml\n\nnetworks:\n  webgateway:\n    driver: bridge\n\n\n\n\nStart it from within the \ntraefik\n folder:\n\n\ndocker-compose up -d\n\n\n\nIn a browser you may open \nhttp://localhost:8080\n to access Tr\u00e6fik's dashboard and observe the following magic.\n\n\nNow, create a folder named \ntest\n and create a \ndocker-compose.yml\n in it with this content:\n\n\nversion: '2'\n\nservices:\n  whoami:\n    image: emilevauge/whoami\n    networks:\n      - web\n    labels:\n      - \ntraefik.backend=whoami\n\n      - \ntraefik.frontend.rule=Host:whoami.docker.localhost\n\n\nnetworks:\n  web:\n    external:\n      name: traefik_webgateway\n\n\n\n\nThen, start and scale it in the \ntest\n folder:\n\n\ndocker-compose up -d\ndocker-compose scale whoami=2\n\n\n\n\nFinally, test load-balancing between the two services \ntest_whoami_1\n and \ntest_whoami_2\n:\n\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#overview", 
            "text": "Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances   But a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.  Traditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.  Here enters Tr\u00e6fik.   Tr\u00e6fik can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.  Run it and forget it!", 
            "title": "Overview"
        }, 
        {
            "location": "/#features", 
            "text": "It's fast  No dependency hell, single binary made with go  Tiny   official  official docker image  Rest API  Hot-reloading of configuration. No need to restart the process  Circuit breakers, retry  Round Robin, rebalancer load-balancers  Metrics (Rest, Prometheus, Datadog, Statd)  Clean AngularJS Web UI  Websocket, HTTP/2, GRPC ready  Access Logs (JSON, CLF)  Let's Encrypt  support (Automatic HTTPS with renewal)  High Availability with cluster mode", 
            "title": "Features"
        }, 
        {
            "location": "/#supported-backends", 
            "text": "Docker  /  Swarm mode  Kubernetes  Mesos  /  Marathon  Rancher  (API, Metadata)  Consul  /  Etcd  /  Zookeeper  /  BoltDB  Eureka  Amazon ECS  Amazon DynamoDB  File  Rest API", 
            "title": "Supported backends"
        }, 
        {
            "location": "/#quickstart", 
            "text": "You can have a quick look at Tr\u00e6fik in this  Katacoda tutorial  that shows how to load balance requests between multiple Docker containers.  Here is a talk given by  Emile Vauge  at  GopherCon 2017 .\nYou will learn Tr\u00e6fik basics in less than 10 minutes.    Here is a talk given by  Ed Robinson  at  ContainerCamp UK  conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.", 
            "title": "Quickstart"
        }, 
        {
            "location": "/#get-it", 
            "text": "", 
            "title": "Get it"
        }, 
        {
            "location": "/#binary", 
            "text": "You can grab the latest binary from the  releases  page and just run it with the  sample configuration file :  ./traefik -c traefik.toml", 
            "title": "Binary"
        }, 
        {
            "location": "/#docker", 
            "text": "Using the tiny Docker image:  docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik", 
            "title": "Docker"
        }, 
        {
            "location": "/#test-it", 
            "text": "You can test Tr\u00e6fik easily using  Docker compose , with this  docker-compose.yml  file in a folder named  traefik :  version: '2'\n\nservices:\n  proxy:\n    image: traefik\n    command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n    networks:\n      - webgateway\n    ports:\n      -  80:80 \n      -  8080:8080 \n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /dev/null:/traefik.toml\n\nnetworks:\n  webgateway:\n    driver: bridge  Start it from within the  traefik  folder:  docker-compose up -d  In a browser you may open  http://localhost:8080  to access Tr\u00e6fik's dashboard and observe the following magic.  Now, create a folder named  test  and create a  docker-compose.yml  in it with this content:  version: '2'\n\nservices:\n  whoami:\n    image: emilevauge/whoami\n    networks:\n      - web\n    labels:\n      -  traefik.backend=whoami \n      -  traefik.frontend.rule=Host:whoami.docker.localhost \n\nnetworks:\n  web:\n    external:\n      name: traefik_webgateway  Then, start and scale it in the  test  folder:  docker-compose up -d\ndocker-compose scale whoami=2  Finally, test load-balancing between the two services  test_whoami_1  and  test_whoami_2 :  $ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Test it"
        }, 
        {
            "location": "/basics/", 
            "text": "Basics\n\n\nConcepts\n\n\nLet's take our example from the \noverview\n again:\n\n\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\n\n\n\n\nLet's zoom on Tr\u00e6fik and have an overview of its internal architecture:\n\n\n\n\n\n\nIncoming requests end on \nentrypoints\n, as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).\n\n\nTraffic is then forwarded to a matching \nfrontend\n. A frontend defines routes from \nentrypoints\n to \nbackends\n.\nRoutes are created using requests fields (\nHost\n, \nPath\n, \nHeaders\n...) and can match or not a request.\n\n\nThe \nfrontend\n will then send the request to a \nbackend\n. A backend can be composed by one or more \nservers\n, and by a load-balancing strategy.\n\n\nFinally, the \nserver\n will forward the request to the corresponding microservice in the private network.\n\n\n\n\nEntrypoints\n\n\nEntrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:\n\n\n\n\na port (80, 443...)\n\n\nSSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)\n\n\nredirection to another entrypoint (redirect \nHTTP\n to \nHTTPS\n)\n\n\n\n\nHere is an example of entrypoints definition:\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nTwo entrypoints are defined \nhttp\n and \nhttps\n.\n\n\nhttp\n listens on port \n80\n and \nhttps\n on port \n443\n.\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nWe also redirect all the traffic from entrypoint \nhttp\n to \nhttps\n.\n\n\n\n\nAnd here is another example with client certificate authentication:\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n  clientCAFiles = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n    [[entryPoints.https.tls.certificates]]\n    certFile = \ntests/traefik.crt\n\n    keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nOne or several files containing Certificate Authorities in PEM format are added.\n\n\nIt is possible to have multiple CA:s in the same file or keep them in separate files.\n\n\n\n\nFrontends\n\n\nA frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.\n\n\nRules may be classified in one of two groups: Modifiers and matchers.\n\n\nModifiers\n\n\nModifier rules only modify the request. They do not have any impact on routing decisions being made.\n\n\nFollowing is the list of existing modifier rules:\n\n\n\n\nAddPrefix: /products\n: Add path prefix to the existing request path prior to forwarding the request to the backend.\n\n\nReplacePath: /serverless-path\n: Replaces the path and adds the old path to the \nX-Replaced-Path\n header. Useful for mapping to AWS Lambda or Google Cloud Functions.\n\n\n\n\nMatchers\n\n\nMatcher rules determine if a particular request should be forwarded to a backend.\n\n\nSeparate multiple rule values by \n,\n (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches). Does not work for \nHeaders\n and \nHeadersRegexp\n.\n\n\nSeparate multiple rule values by \n;\n (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).\n\n\nYou can optionally enable \npassHostHeader\n to forward client \nHost\n header to the backend. You can also optionally enable \npassTLSCert\n to forward TLS Client certificates to the backend.\n\n\nFollowing is the list of existing matcher rules along with examples:\n\n\n\n\nHeaders: Content-Type, application/json\n: Match HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.\n\n\nHeadersRegexp: Content-Type, application/(text|json)\n: Match HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.\n\n\nHost: traefik.io, www.traefik.io\n: Match request host. It accepts a sequence of literal hosts.\n\n\nHostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io\n: Match request host. It accepts a sequence of literal and regular expression hosts.\n\n\nMethod: GET, POST, PUT\n: Match request HTTP method. It accepts a sequence of HTTP methods.\n\n\nPath: /products/, /articles/{category}/{id:[0-9]+}\n: Match exact request path. It accepts a sequence of literal and regular expression paths.\n\n\nPathStrip: /products/\n: Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.\n\n\nPathStripRegex: /articles/{category}/{id:[0-9]+}\n: Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.\n\n\nPathPrefix: /products/, /articles/{category}/{id:[0-9]+}\n: Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.\n\n\nPathPrefixStrip: /products/\n: Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\nPathPrefixStripRegex: /articles/{category}/{id:[0-9]+}\n: Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\nQuery: foo=bar, bar=baz\n: Match Query String parameters. It accepts a sequence of key=value pairs.\n\n\n\n\nIn order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by \nGo's regexp package\n may be used. Example: \n/posts/{id:[0-9]+}\n.\n\n\n(Note that the variable has no special meaning; however, it is required by the gorilla/mux dependency which embeds the regular expression and defines the syntax.)\n\n\nPath Matcher Usage Guidelines\n\n\nThis section explains when to use the various path matchers.\n\n\nUse \nPath\n if your backend listens on the exact path only. For instance, \nPath: /products\n would match \n/products\n but not \n/products/shoes\n.\n\n\nUse a \n*Prefix*\n matcher if your backend listens on a particular base path but also serves requests on sub-paths. For instance, \nPathPrefix: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n. Since the path is forwarded as-is, your backend is expected to listen on \n/products\n.\n\n\nUse a \n*Strip\n matcher if your backend listens on the root path (\n/\n) but should be routeable on a specific prefix. For instance, \nPathPrefixStrip: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n. Since the path is stripped prior to forwarding, your backend is expected to listen on \n/\n.\nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs. Continuing on the example, the backend should return \n/products/shoes/image.png\n (and not \n/images.png\n which Traefik would likely not be able to associate with the same backend). The \nX-Forwarded-Prefix\n header (available since Traefik 1.3) can be queried to build such URLs dynamically.\n\n\nInstead of distinguishing your backends by path only, you can add a Host matcher to the mix. That way, namespacing of your backends happens on the basis of hosts in addition to paths.\n\n\nExamples\n\n\nHere is an example of frontends definition:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost,test2.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHostRegexp:localhost,{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\n\n\nThree frontends are defined: \nfrontend1\n, \nfrontend2\n and \nfrontend3\n\n\nfrontend1\n will forward the traffic to the \nbackend2\n if the rule \nHost:test.localhost,test2.localhost\n is matched\n\n\nfrontend2\n will forward the traffic to the \nbackend1\n if the rule \nHost:localhost,{subdomain:[a-z]+}.localhost\n is matched (forwarding client \nHost\n header to the backend)\n\n\nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched\n\n\n\n\nCombining multiple rules\n\n\nAs seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost\n\n    [frontends.frontend3.routes.test_2]\n    rule = \nPath:/test\n\n\n\n\n\nHere \nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched.\nYou can also use the notation using a \n;\n separator, same result:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\nFinally, you can create a rule to bind multiple domains or Path to a frontend, using the \n,\n separator:\n\n\n [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:test1.localhost,test2.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nPath:/test1,/test2\n\n\n\n\n\nRules Order\n\n\nWhen combining \nModifier\n rules with \nMatcher\n rules, it is important to remember that \nModifier\n rules \nALWAYS\n apply after the \nMatcher\n rules.\n\nThe following rules are both \nMatchers\n and \nModifiers\n, so the \nMatcher\n portion of the rule will apply first, and the \nModifier\n will apply later.\n\n\n\n\nPathStrip\n\n\nPathStripRegex\n\n\nPathPrefixStrip\n\n\nPathPrefixStripRegex\n\n\n\n\nModifiers\n will be applied in a pre-determined order regardless of their order in the \nrule\n configuration section.\n\n\n\n\nPathStrip\n\n\nPathPrefixStrip\n\n\nPathStripRegex\n\n\nPathPrefixStripRegex\n\n\nAddPrefix\n\n\nReplacePath\n\n\n\n\nPriorities\n\n\nBy default, routes will be sorted (in descending order) using rules length (to avoid path overlap):\n\nPathPrefix:/12345\n will be matched before \nPathPrefix:/1234\n that will be matched before \nPathPrefix:/1\n.\n\n\nYou can customize priority by frontend:\n\n\n  [frontends]\n    [frontends.frontend1]\n    backend = \nbackend1\n\n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefix:/to\n\n    [frontends.frontend2]\n    priority = 5\n    backend = \nbackend2\n\n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule = \nPathPrefix:/toto\n\n\n\n\n\nHere, \nfrontend1\n will be matched before \nfrontend2\n (\n10 \n 5\n).\n\n\nCustom headers\n\n\nCustom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules. This allows for setting headers such as \nX-Script-Name\n to be added to the request, or custom headers to be added to the response:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header = \nTrue\n\n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name = \ntest\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheese\n\n\n\n\n\nIn this example, all matches to the path \n/cheese\n will have the \nX-Script-Name\n header added to the proxied request, and the \nX-Custom-Response-Header\n added to the response.\n\n\nSecurity headers\n\n\nSecurity related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above. This functionality allows for some easy security features to quickly be set. An example of some of the security headers:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheddar\n\n  [frontends.frontend2]\n  backend = \nbackend2\n\n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule = \nPathPrefixStrip:/stilton\n\n\n\n\n\nIn this example, traffic routed through the first frontend will have the \nX-Frame-Options\n header set to \nDENY\n, and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.\n\n\nBackends\n\n\nA backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\nVarious methods of load-balancing are supported:\n\n\n\n\nwrr\n: Weighted Round Robin\n\n\ndrr\n: Dynamic Round Robin: increases weights on servers that perform better than others. It also rolls back to original weights if the servers have changed.\n\n\n\n\nA circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.\n\n\nIt can be configured using:\n\n\n\n\nMethods: \nLatencyAtQuantileMS\n, \nNetworkErrorRatio\n, \nResponseCodeRatio\n\n\nOperators:  \nAND\n, \nOR\n, \nEQ\n, \nNEQ\n, \nLT\n, \nLE\n, \nGT\n, \nGE\n\n\n\n\nFor example:\n\n\n\n\nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window for a frontend\n\n\nLatencyAtQuantileMS(50.0) \n 50\n:  watch latency at quantile in milliseconds.\n\n\nResponseCodeRatio(500, 600, 0, 600) \n 0.5\n: ratio of response codes in range [500-600) to  [0-600)\n\n\n\n\nTo proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.\n\n\nMaximum connections can be configured by specifying an integer value for \nmaxconn.amount\n and\n\nmaxconn.extractorfunc\n which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc = \nrequest.host\n\n\n\n\n\n\n\nbackend1\n will return \nHTTP code 429 Too Many Requests\n if there are already 10 requests in progress for the same Host header.\n\n\nAnother possible value for \nextractorfunc\n is \nclient.ip\n which will categorize requests based on client source ip.\n\n\nLastly \nextractorfunc\n can take the value of \nrequest.header.ANY_HEADER\n which will categorize requests based on \nANY_HEADER\n that you provide.\n\n\n\n\nSticky sessions are supported with both load balancers. When sticky sessions are enabled, a cookie called \n_TRAEFIK_BACKEND\n is set on the initial\nrequest. On subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy. If not, a new backend\nwill be assigned.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true\n\n\n\n\nA health check can be configured in order to remove a backend from LB rotation\nas long as it keeps returning HTTP status codes other than 200 OK to HTTP GET\nrequests periodically carried out by Traefik. The check is defined by a path\nappended to the backend URL and an interval (given in a format understood by \ntime.ParseDuration\n) specifying how\noften the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds.\nBy default, the port of the backend server is used, however, this may be overridden.  \n\n\nA recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n      path = \n/health\n\n      interval = \n10s\n\n\n\n\n\nTo use a different port for the healthcheck:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n      path = \n/health\n\n      interval = \n10s\n\n      port = 8080\n\n\n\n\nServers\n\n\nServers are simply defined using a \nURL\n. You can also apply a custom \nweight\n to each server (this will be used by load-balancing).\n\n\nHere is an example of backends and servers definition:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n\n\n\n\n\nTwo backends are defined: \nbackend1\n and \nbackend2\n\n\nbackend1\n will forward the traffic to two servers: \nhttp://172.17.0.2:80\"\n with weight \n10\n and \nhttp://172.17.0.3:80\n with weight \n1\n using default \nwrr\n load-balancing strategy.\n\n\nbackend2\n will forward the traffic to two servers: \nhttp://172.17.0.4:80\"\n with weight \n1\n and \nhttp://172.17.0.5:80\n with weight \n2\n using \ndrr\n load-balancing strategy.\n\n\na circuit breaker is added on \nbackend1\n using the expression \nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window\n\n\n\n\nCustom Error pages\n\n\nCustom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.\nIn the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.\nNote, the 503.html page itself is not hosted on traefik, but some other infrastructure.   \n\n\n[frontends]\n  [frontends.website]\n  backend = \nwebsite\n\n  [errors]\n    [error.network]\n    status = [\n500-599\n]\n    backend = \nerror\n\n    query = \n/{status}.html\n\n  [frontends.website.routes.website]\n  rule = \nHost: website.mydomain.com\n\n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url = \nhttps://1.2.3.4\n\n  [backends.error]\n    [backends.error.servers.error]\n    url = \nhttp://2.3.4.5\n\n\n\n\n\nIn the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so: \nquery = \"/500s.html\"\n\n\nNow the 500s.html error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the 500s.html page will be returned for status codes 500 through, and including, 599.\n\n\nConfiguration\n\n\nTr\u00e6fik's configuration has two parts:\n\n\n\n\nThe \nstatic Tr\u00e6fik configuration\n which is loaded only at the beginning.\n\n\nThe \ndynamic Tr\u00e6fik configuration\n which can be hot-reloaded (no need to restart the process).\n\n\n\n\nStatic Tr\u00e6fik configuration\n\n\nThe static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.\n\n\nTr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:\n\n\n\n\nKey-value store\n\n\nArguments\n\n\nConfiguration file\n\n\nDefault\n\n\n\n\nIt means that arguments override configuration file, and key-value store overrides arguments.\n\n\nNote that the provider-enabling argument parameters (e.g., \n--docker\n) set all default values for the specific provider. It must not be used if a configuration source with less precedence wants to set a non-default provider value.\n\n\nConfiguration file\n\n\nBy default, Tr\u00e6fik will try to find a \ntraefik.toml\n in the following places:\n\n\n\n\n/etc/traefik/\n\n\n$HOME/.traefik/\n\n\n.\n \nthe working directory\n\n\n\n\nYou can override this by setting a \nconfigFile\n argument:\n\n\n$ traefik --configFile=foo/bar/myconfigfile.toml\n\n\n\n\nPlease refer to the \nglobal configuration\n section to get documentation on it.\n\n\nArguments\n\n\nEach argument (and command) is described in the help section:\n\n\n$ traefik --help\n\n\n\n\nNote that all default values will be displayed as well.\n\n\nKey-value stores\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nPlease refer to the \nUser Guide Key-value store configuration\n section to get documentation on it.\n\n\nDynamic Tr\u00e6fik configuration\n\n\nThe dynamic configuration concerns :\n\n\n\n\nFrontends\n\n\nBackends\n\n\nServers\n\n\n\n\nTr\u00e6fik can hot-reload those rules which could be provided by \nmultiple configuration backends\n.\n\n\nWe only need to enable \nwatch\n option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.\n\n\nPlease refer to the \nconfiguration backends\n section to get documentation on it.\n\n\nCommands\n\n\nUsage: \ntraefik\u00a0[command] [--flag=flag_argument]\n\n\nList of Tr\u00e6fik available\u00a0commands with description :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\n\n\n\nversion\n : Print\u00a0version\u00a0\n\n\nstoreconfig\n : Store the static traefik configuration into a Key-value stores.\u00a0Please refer to the \nStore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nbug\n: The easiest way to submit a pre-filled issue.\n\n\nhealthcheck\n: Calls traefik \n/ping\n to check health.\n\n\n\n\nEach command may have related flags.\nAll those related flags will be displayed with :\n\n\n$ traefik [command] --help\n\n\n\n\nNote that each command is described at the beginning of the help section:\n\n\n$ traefik --help\n\n\n\n\nCommand: bug\n\n\nHere is the easiest way to submit a pre-filled issue on \nTr\u00e6fik GitHub\n.\n\n\n$ traefik bug\n\n\n\n\nSee https://www.youtube.com/watch?v=Lyz62L8m93I.\n\n\nCommand: healthcheck\n\n\nThis command allows to check the health of Traefik. Its exit status is \n0\n if Traefik is healthy and \n1\n if it is unhealthy.\nThis can be used with Docker \nHEALTHCHECK\n instruction or any other health check orchestration mechanism.\n\n\nNote: the \nweb\n provider must be enabled to allow \n/ping\n calls by the \nhealthcheck\n command.\n\n\n$ traefik healthcheck\nOK: http://:8082/ping\n\n\n\n\nLog Rotation\n\n\nTraefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.  This allows the logs\nto be rotated and processed by an external program, such as \nlogrotate\n.\n\n\nNote that this does not work on Windows due to the lack of USR signals.", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#basics", 
            "text": "", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#concepts", 
            "text": "Let's take our example from the  overview  again:   Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances     Let's zoom on Tr\u00e6fik and have an overview of its internal architecture:    Incoming requests end on  entrypoints , as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).  Traffic is then forwarded to a matching  frontend . A frontend defines routes from  entrypoints  to  backends .\nRoutes are created using requests fields ( Host ,  Path ,  Headers ...) and can match or not a request.  The  frontend  will then send the request to a  backend . A backend can be composed by one or more  servers , and by a load-balancing strategy.  Finally, the  server  will forward the request to the corresponding microservice in the private network.", 
            "title": "Concepts"
        }, 
        {
            "location": "/basics/#entrypoints", 
            "text": "Entrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:   a port (80, 443...)  SSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)  redirection to another entrypoint (redirect  HTTP  to  HTTPS )   Here is an example of entrypoints definition:  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key    Two entrypoints are defined  http  and  https .  http  listens on port  80  and  https  on port  443 .  We enable SSL on  https  by giving a certificate and a key.  We also redirect all the traffic from entrypoint  http  to  https .   And here is another example with client certificate authentication:  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n  clientCAFiles = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n    [[entryPoints.https.tls.certificates]]\n    certFile =  tests/traefik.crt \n    keyFile =  tests/traefik.key    We enable SSL on  https  by giving a certificate and a key.  One or several files containing Certificate Authorities in PEM format are added.  It is possible to have multiple CA:s in the same file or keep them in separate files.", 
            "title": "Entrypoints"
        }, 
        {
            "location": "/basics/#frontends", 
            "text": "A frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.  Rules may be classified in one of two groups: Modifiers and matchers.", 
            "title": "Frontends"
        }, 
        {
            "location": "/basics/#modifiers", 
            "text": "Modifier rules only modify the request. They do not have any impact on routing decisions being made.  Following is the list of existing modifier rules:   AddPrefix: /products : Add path prefix to the existing request path prior to forwarding the request to the backend.  ReplacePath: /serverless-path : Replaces the path and adds the old path to the  X-Replaced-Path  header. Useful for mapping to AWS Lambda or Google Cloud Functions.", 
            "title": "Modifiers"
        }, 
        {
            "location": "/basics/#matchers", 
            "text": "Matcher rules determine if a particular request should be forwarded to a backend.  Separate multiple rule values by  ,  (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches). Does not work for  Headers  and  HeadersRegexp .  Separate multiple rule values by  ;  (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).  You can optionally enable  passHostHeader  to forward client  Host  header to the backend. You can also optionally enable  passTLSCert  to forward TLS Client certificates to the backend.  Following is the list of existing matcher rules along with examples:   Headers: Content-Type, application/json : Match HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.  HeadersRegexp: Content-Type, application/(text|json) : Match HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.  Host: traefik.io, www.traefik.io : Match request host. It accepts a sequence of literal hosts.  HostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io : Match request host. It accepts a sequence of literal and regular expression hosts.  Method: GET, POST, PUT : Match request HTTP method. It accepts a sequence of HTTP methods.  Path: /products/, /articles/{category}/{id:[0-9]+} : Match exact request path. It accepts a sequence of literal and regular expression paths.  PathStrip: /products/ : Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.  PathStripRegex: /articles/{category}/{id:[0-9]+} : Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.  PathPrefix: /products/, /articles/{category}/{id:[0-9]+} : Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.  PathPrefixStrip: /products/ : Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.  PathPrefixStripRegex: /articles/{category}/{id:[0-9]+} : Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.  Query: foo=bar, bar=baz : Match Query String parameters. It accepts a sequence of key=value pairs.   In order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by  Go's regexp package  may be used. Example:  /posts/{id:[0-9]+} .  (Note that the variable has no special meaning; however, it is required by the gorilla/mux dependency which embeds the regular expression and defines the syntax.)", 
            "title": "Matchers"
        }, 
        {
            "location": "/basics/#path-matcher-usage-guidelines", 
            "text": "This section explains when to use the various path matchers.  Use  Path  if your backend listens on the exact path only. For instance,  Path: /products  would match  /products  but not  /products/shoes .  Use a  *Prefix*  matcher if your backend listens on a particular base path but also serves requests on sub-paths. For instance,  PathPrefix: /products  would match  /products  but also  /products/shoes  and  /products/shirts . Since the path is forwarded as-is, your backend is expected to listen on  /products .  Use a  *Strip  matcher if your backend listens on the root path ( / ) but should be routeable on a specific prefix. For instance,  PathPrefixStrip: /products  would match  /products  but also  /products/shoes  and  /products/shirts . Since the path is stripped prior to forwarding, your backend is expected to listen on  / .\nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs. Continuing on the example, the backend should return  /products/shoes/image.png  (and not  /images.png  which Traefik would likely not be able to associate with the same backend). The  X-Forwarded-Prefix  header (available since Traefik 1.3) can be queried to build such URLs dynamically.  Instead of distinguishing your backends by path only, you can add a Host matcher to the mix. That way, namespacing of your backends happens on the basis of hosts in addition to paths.", 
            "title": "Path Matcher Usage Guidelines"
        }, 
        {
            "location": "/basics/#examples", 
            "text": "Here is an example of frontends definition:  [frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost,test2.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  HostRegexp:localhost,{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test    Three frontends are defined:  frontend1 ,  frontend2  and  frontend3  frontend1  will forward the traffic to the  backend2  if the rule  Host:test.localhost,test2.localhost  is matched  frontend2  will forward the traffic to the  backend1  if the rule  Host:localhost,{subdomain:[a-z]+}.localhost  is matched (forwarding client  Host  header to the backend)  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched", 
            "title": "Examples"
        }, 
        {
            "location": "/basics/#combining-multiple-rules", 
            "text": "As seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost \n    [frontends.frontend3.routes.test_2]\n    rule =  Path:/test   Here  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched.\nYou can also use the notation using a  ;  separator, same result:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test   Finally, you can create a rule to bind multiple domains or Path to a frontend, using the  ,  separator:   [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:test1.localhost,test2.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Path:/test1,/test2", 
            "title": "Combining multiple rules"
        }, 
        {
            "location": "/basics/#rules-order", 
            "text": "When combining  Modifier  rules with  Matcher  rules, it is important to remember that  Modifier  rules  ALWAYS  apply after the  Matcher  rules. \nThe following rules are both  Matchers  and  Modifiers , so the  Matcher  portion of the rule will apply first, and the  Modifier  will apply later.   PathStrip  PathStripRegex  PathPrefixStrip  PathPrefixStripRegex   Modifiers  will be applied in a pre-determined order regardless of their order in the  rule  configuration section.   PathStrip  PathPrefixStrip  PathStripRegex  PathPrefixStripRegex  AddPrefix  ReplacePath", 
            "title": "Rules Order"
        }, 
        {
            "location": "/basics/#priorities", 
            "text": "By default, routes will be sorted (in descending order) using rules length (to avoid path overlap): PathPrefix:/12345  will be matched before  PathPrefix:/1234  that will be matched before  PathPrefix:/1 .  You can customize priority by frontend:    [frontends]\n    [frontends.frontend1]\n    backend =  backend1 \n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefix:/to \n    [frontends.frontend2]\n    priority = 5\n    backend =  backend2 \n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule =  PathPrefix:/toto   Here,  frontend1  will be matched before  frontend2  ( 10   5 ).", 
            "title": "Priorities"
        }, 
        {
            "location": "/basics/#custom-headers", 
            "text": "Custom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules. This allows for setting headers such as  X-Script-Name  to be added to the request, or custom headers to be added to the response:  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header =  True \n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name =  test \n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheese   In this example, all matches to the path  /cheese  will have the  X-Script-Name  header added to the proxied request, and the  X-Custom-Response-Header  added to the response.", 
            "title": "Custom headers"
        }, 
        {
            "location": "/basics/#security-headers", 
            "text": "Security related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above. This functionality allows for some easy security features to quickly be set. An example of some of the security headers:  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheddar \n  [frontends.frontend2]\n  backend =  backend2 \n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule =  PathPrefixStrip:/stilton   In this example, traffic routed through the first frontend will have the  X-Frame-Options  header set to  DENY , and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.", 
            "title": "Security headers"
        }, 
        {
            "location": "/basics/#backends", 
            "text": "A backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\nVarious methods of load-balancing are supported:   wrr : Weighted Round Robin  drr : Dynamic Round Robin: increases weights on servers that perform better than others. It also rolls back to original weights if the servers have changed.   A circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.  It can be configured using:   Methods:  LatencyAtQuantileMS ,  NetworkErrorRatio ,  ResponseCodeRatio  Operators:   AND ,  OR ,  EQ ,  NEQ ,  LT ,  LE ,  GT ,  GE   For example:   NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window for a frontend  LatencyAtQuantileMS(50.0)   50 :  watch latency at quantile in milliseconds.  ResponseCodeRatio(500, 600, 0, 600)   0.5 : ratio of response codes in range [500-600) to  [0-600)   To proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.  Maximum connections can be configured by specifying an integer value for  maxconn.amount  and maxconn.extractorfunc  which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc =  request.host    backend1  will return  HTTP code 429 Too Many Requests  if there are already 10 requests in progress for the same Host header.  Another possible value for  extractorfunc  is  client.ip  which will categorize requests based on client source ip.  Lastly  extractorfunc  can take the value of  request.header.ANY_HEADER  which will categorize requests based on  ANY_HEADER  that you provide.   Sticky sessions are supported with both load balancers. When sticky sessions are enabled, a cookie called  _TRAEFIK_BACKEND  is set on the initial\nrequest. On subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy. If not, a new backend\nwill be assigned.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true  A health check can be configured in order to remove a backend from LB rotation\nas long as it keeps returning HTTP status codes other than 200 OK to HTTP GET\nrequests periodically carried out by Traefik. The check is defined by a path\nappended to the backend URL and an interval (given in a format understood by  time.ParseDuration ) specifying how\noften the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds.\nBy default, the port of the backend server is used, however, this may be overridden.    A recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n      path =  /health \n      interval =  10s   To use a different port for the healthcheck:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n      path =  /health \n      interval =  10s \n      port = 8080", 
            "title": "Backends"
        }, 
        {
            "location": "/basics/#servers", 
            "text": "Servers are simply defined using a  URL . You can also apply a custom  weight  to each server (this will be used by load-balancing).  Here is an example of backends and servers definition:  [backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2   Two backends are defined:  backend1  and  backend2  backend1  will forward the traffic to two servers:  http://172.17.0.2:80\"  with weight  10  and  http://172.17.0.3:80  with weight  1  using default  wrr  load-balancing strategy.  backend2  will forward the traffic to two servers:  http://172.17.0.4:80\"  with weight  1  and  http://172.17.0.5:80  with weight  2  using  drr  load-balancing strategy.  a circuit breaker is added on  backend1  using the expression  NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window", 
            "title": "Servers"
        }, 
        {
            "location": "/basics/#custom-error-pages", 
            "text": "Custom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.\nIn the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.\nNote, the 503.html page itself is not hosted on traefik, but some other infrastructure.     [frontends]\n  [frontends.website]\n  backend =  website \n  [errors]\n    [error.network]\n    status = [ 500-599 ]\n    backend =  error \n    query =  /{status}.html \n  [frontends.website.routes.website]\n  rule =  Host: website.mydomain.com \n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url =  https://1.2.3.4 \n  [backends.error]\n    [backends.error.servers.error]\n    url =  http://2.3.4.5   In the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so:  query = \"/500s.html\"  Now the 500s.html error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the 500s.html page will be returned for status codes 500 through, and including, 599.", 
            "title": "Custom Error pages"
        }, 
        {
            "location": "/basics/#configuration", 
            "text": "Tr\u00e6fik's configuration has two parts:   The  static Tr\u00e6fik configuration  which is loaded only at the beginning.  The  dynamic Tr\u00e6fik configuration  which can be hot-reloaded (no need to restart the process).", 
            "title": "Configuration"
        }, 
        {
            "location": "/basics/#static-trfik-configuration", 
            "text": "The static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.  Tr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:   Key-value store  Arguments  Configuration file  Default   It means that arguments override configuration file, and key-value store overrides arguments.  Note that the provider-enabling argument parameters (e.g.,  --docker ) set all default values for the specific provider. It must not be used if a configuration source with less precedence wants to set a non-default provider value.", 
            "title": "Static Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#configuration-file", 
            "text": "By default, Tr\u00e6fik will try to find a  traefik.toml  in the following places:   /etc/traefik/  $HOME/.traefik/  .   the working directory   You can override this by setting a  configFile  argument:  $ traefik --configFile=foo/bar/myconfigfile.toml  Please refer to the  global configuration  section to get documentation on it.", 
            "title": "Configuration file"
        }, 
        {
            "location": "/basics/#arguments", 
            "text": "Each argument (and command) is described in the help section:  $ traefik --help  Note that all default values will be displayed as well.", 
            "title": "Arguments"
        }, 
        {
            "location": "/basics/#key-value-stores", 
            "text": "Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb   Please refer to the  User Guide Key-value store configuration  section to get documentation on it.", 
            "title": "Key-value stores"
        }, 
        {
            "location": "/basics/#dynamic-trfik-configuration", 
            "text": "The dynamic configuration concerns :   Frontends  Backends  Servers   Tr\u00e6fik can hot-reload those rules which could be provided by  multiple configuration backends .  We only need to enable  watch  option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.  Please refer to the  configuration backends  section to get documentation on it.", 
            "title": "Dynamic Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#commands", 
            "text": "Usage:  traefik\u00a0[command] [--flag=flag_argument]  List of Tr\u00e6fik available\u00a0commands with description :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0   version  : Print\u00a0version\u00a0  storeconfig  : Store the static traefik configuration into a Key-value stores.\u00a0Please refer to the  Store Tr\u00e6fik configuration  section to get documentation on it.  bug : The easiest way to submit a pre-filled issue.  healthcheck : Calls traefik  /ping  to check health.   Each command may have related flags.\nAll those related flags will be displayed with :  $ traefik [command] --help  Note that each command is described at the beginning of the help section:  $ traefik --help", 
            "title": "Commands"
        }, 
        {
            "location": "/basics/#command-bug", 
            "text": "Here is the easiest way to submit a pre-filled issue on  Tr\u00e6fik GitHub .  $ traefik bug  See https://www.youtube.com/watch?v=Lyz62L8m93I.", 
            "title": "Command: bug"
        }, 
        {
            "location": "/basics/#command-healthcheck", 
            "text": "This command allows to check the health of Traefik. Its exit status is  0  if Traefik is healthy and  1  if it is unhealthy.\nThis can be used with Docker  HEALTHCHECK  instruction or any other health check orchestration mechanism.  Note: the  web  provider must be enabled to allow  /ping  calls by the  healthcheck  command.  $ traefik healthcheck\nOK: http://:8082/ping", 
            "title": "Command: healthcheck"
        }, 
        {
            "location": "/basics/#log-rotation", 
            "text": "Traefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.  This allows the logs\nto be rotated and processed by an external program, such as  logrotate .  Note that this does not work on Windows due to the lack of USR signals.", 
            "title": "Log Rotation"
        }, 
        {
            "location": "/configuration/commons/", 
            "text": "Global Configuration\n\n\nMain Section\n\n\n################################################################\n# Global configuration\n################################################################\n\n# Duration to give active requests a chance to finish before Traefik stops.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# Note: in this time frame no new requests are accepted.\n#\n# Optional\n# Default: \n10s\n\n#\n# graceTimeOut = \n10s\n\n\n# Enable debug mode\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Traefik logs file\n# If not defined, logs to stdout\n#\n# Optional\n#\n# traefikLogsFile = \nlog/traefik.log\n\n\n# Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n# Optional\n#\n# accessLogsFile = \nlog/access.log\n\n\n# Log level\n#\n# Optional\n# Default: \nERROR\n\n# Accepted values, in order of severity: \nDEBUG\n, \nINFO\n, \nWARN\n, \nERROR\n, \nFATAL\n, \nPANIC\n\n# Messages at and above the selected level will be logged.\n#\n# logLevel = \nERROR\n\n\n# Backends throttle duration: minimum duration in seconds between 2 events from providers\n# before applying a new configuration. It avoids unnecessary reloads if multiples events\n# are sent in a short amount of time.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default: \n2s\n\n#\n# ProvidersThrottleDuration = \n2s\n\n\n# IdleTimeout\n# \n# DEPRECATED - see [respondingTimeouts] section. In the case both settings are configured, the deprecated option will\n# be overwritten.\n#\n# IdleTimeout is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\n# This is set to enforce closing of stale client connections.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n180s\n\n#\n# IdleTimeout = \n360s\n\n\n# Controls the maximum idle (keep-alive) connections to keep per-host. If zero, DefaultMaxIdleConnsPerHost\n# from the Go standard library net/http module is used.\n# If you encounter 'too many open files' errors, you can either increase this\n# value or change the `ulimit`.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# Note: This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA. This certificates will be use for backends calls.\n# Note: You can use file path or cert content directly\n# Optional\n# Default: []\n#\n# RootCAs = [ \n/mycert.cert\n ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [\nhttp\n]\n#\n# defaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n\n\n\nConstraints\n\n\nIn a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.\n\n\nTr\u00e6fik filters services according to service attributes/tags set in your configuration backends.\n\n\nSupported backends:\n\n\n\n\nDocker\n\n\nConsul K/V\n\n\nBoltDB\n\n\nZookeeper\n\n\nEtcd\n\n\nConsul Catalog\n\n\nRancher\n\n\nMarathon\n\n\nKubernetes (using a provider-specific mechanism based on label selectors)\n\n\n\n\nSupported filters:\n\n\n\n\ntag\n\n\n\n\n# Constraints definition\n#\n# Optional\n#\n# Simple matching constraint\n# constraints = [\ntag==api\n]\n\n# Simple mismatching constraint\n# constraints = [\ntag!=api\n]\n\n# Globbing\n# constraints = [\ntag==us-*\n]\n\n# Multiple constraints\n#   - \ntag==\n must match with at least one tag\n#   - \ntag!=\n must match with none of tags\n# constraints = [\ntag!=us-*\n, \ntag!=asia-*\n]\n\n# Backend-specific constraint\n# [consulCatalog]\n#   endpoint = 127.0.0.1:8500\n#   constraints = [\ntag==api\n]\n\n# [consulCatalog]\n#   endpoint = 127.0.0.1:8500\n#   constraints = [\ntag==api\n, \ntag!=v*-beta\n]\n\n\n\n\nAccess Log Definition\n\n\nAccess logs are written when \n[accessLog]\n is defined. \nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.\n\n\nTo enable access logs using the default settings just add the \n[accessLog]\n entry.\n\n\n[accessLog]\n\n\n\n\nTo write the logs into a logfile specify the \nfilePath\n.\n\n\n[accessLog]\n  filePath = \n/path/to/access.log\n\n\n\n\n\nTo write JSON format logs, specify \njson\n as the format:\n\n\n[accessLog]\n  filePath   = \n/path/to/access.log\n\n  format     = \njson\n\n\n\n\n\nEntry Points Definition\n\n\n# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nRedirect HTTP to HTTPS\n\n\n# To redirect an http entrypoint to an https entrypoint (with SNI support):\n#\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nRewriting URL\n\n\n# To redirect an entrypoint rewriting the URL:\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      regex = \n^http://localhost/(.*)\n\n      replacement = \nhttp://mydomain/$1\n\n\n\n\n\nTLS Mutual Authentication\n\n\n# Only accept clients that present a certificate signed by a specified\n# Certificate Authority (CA)\n# ClientCAFiles can be configured with multiple CA:s in the same file or\n# use multiple files containing one or several CA:s. The CA:s has to be in PEM format.\n# All clients will be required to present a valid cert.\n# The requirement will apply to all server certs in the entrypoint\n# In the example below both snitest.com and snitest.org will require client certs\n#\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n  ClientCAFiles = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n    [[entryPoints.https.tls.certificates]]\n    CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n    KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n    [[entryPoints.https.tls.certificates]]\n    CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n    KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nBasic \n Digest Authentication\n\n\n# To enable basic auth on an entrypoint\n#\n# with 2 user/pass: test:test and test2:test2\n# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones.\n# Users can be specified directly in the toml file, or indirectly by referencing an external file;\n# if both are provided, the two are merged, with external file contents having precedence.\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n  usersFile = \n/path/to/.htpasswd\n\n\n\n\n\n# To enable digest auth on an entrypoint\n#\n# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n# You can use htdigest to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file;\n# if both are provided, the two are merged, with external file contents having precedence\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05 \n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\n  usersFile = \n/path/to/.htdigest\n\n\n\n\n\nSpecify Minimum TLS Version\n\n\n# To specify an https entrypoint with a minimum TLS version, \n# and specifying an array of cipher suites (from crypto/tls):\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n    MinVersion = \nVersionTLS12\n\n    CipherSuites = [\nTLS_RSA_WITH_AES_256_GCM_SHA384\n]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nCompression\n\n\n# To enable compression support using gzip format:\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  compress = true\n\n\n\n\nWhitelisting\n\n\n# To enable IP whitelisting at the entrypoint level:\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  whiteListSourceRange = [\n127.0.0.1/32\n]\n\n\n\n\nProxyProtocol Support\n\n\n# To enable ProxyProtocol support (https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt):\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  proxyprotocol = true\n\n\n\n\nRetry Configuration\n\n\n# Enable retry sending request if network error\n#\n# Optional\n#\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3\n\n\n\n\nHealth Check Configuration\n\n\n# Enable custom health check options.\n#\n# Optional\n#\n[healthcheck]\n\n# Set the default health check interval. Will only be effective if health check\n# paths are defined. Given provider-specific support, the value may be\n# overridden on a per-backend basis.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default: \n30s\n\n#\n# interval = \n30s\n\n\n\n\n\nResponding Timeouts\n\n\n# respondingTimeouts are timeouts for incoming requests to the Traefik instance.\n#\n# Optional\n# \n[respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n# \n# Optional\n# Default: \n0s\n\n# \n# readTimeout = \n5s\n\n\n# writeTimeout is the maximum duration before timing out writes of the response. It covers the time from the end of \n# the request header read to the end of the response write.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n0s\n\n# \n# writeTimeout = \n5s\n\n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n180s\n\n#\n# idleTimeout = \n360s\n\n\n\n\n\n\nForwarding Timeouts\n\n\n# forwardingTimeouts are timeouts for requests forwarded to the backend servers.\n#\n# Optional\n# \n[forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established. \n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n# \n# Optional\n# Default: \n30s\n\n# \n# dialTimeout = \n30s\n\n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any). \n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n0s\n\n# \n# responseHeaderTimeout = \n0s", 
            "title": "Commons"
        }, 
        {
            "location": "/configuration/commons/#global-configuration", 
            "text": "", 
            "title": "Global Configuration"
        }, 
        {
            "location": "/configuration/commons/#main-section", 
            "text": "################################################################\n# Global configuration\n################################################################\n\n# Duration to give active requests a chance to finish before Traefik stops.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# Note: in this time frame no new requests are accepted.\n#\n# Optional\n# Default:  10s \n#\n# graceTimeOut =  10s \n\n# Enable debug mode\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Traefik logs file\n# If not defined, logs to stdout\n#\n# Optional\n#\n# traefikLogsFile =  log/traefik.log \n\n# Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n# Optional\n#\n# accessLogsFile =  log/access.log \n\n# Log level\n#\n# Optional\n# Default:  ERROR \n# Accepted values, in order of severity:  DEBUG ,  INFO ,  WARN ,  ERROR ,  FATAL ,  PANIC \n# Messages at and above the selected level will be logged.\n#\n# logLevel =  ERROR \n\n# Backends throttle duration: minimum duration in seconds between 2 events from providers\n# before applying a new configuration. It avoids unnecessary reloads if multiples events\n# are sent in a short amount of time.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default:  2s \n#\n# ProvidersThrottleDuration =  2s \n\n# IdleTimeout\n# \n# DEPRECATED - see [respondingTimeouts] section. In the case both settings are configured, the deprecated option will\n# be overwritten.\n#\n# IdleTimeout is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\n# This is set to enforce closing of stale client connections.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  180s \n#\n# IdleTimeout =  360s \n\n# Controls the maximum idle (keep-alive) connections to keep per-host. If zero, DefaultMaxIdleConnsPerHost\n# from the Go standard library net/http module is used.\n# If you encounter 'too many open files' errors, you can either increase this\n# value or change the `ulimit`.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# Note: This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA. This certificates will be use for backends calls.\n# Note: You can use file path or cert content directly\n# Optional\n# Default: []\n#\n# RootCAs = [  /mycert.cert  ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [ http ]\n#\n# defaultEntryPoints = [ http ,  https ]", 
            "title": "Main Section"
        }, 
        {
            "location": "/configuration/commons/#constraints", 
            "text": "In a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.  Tr\u00e6fik filters services according to service attributes/tags set in your configuration backends.  Supported backends:   Docker  Consul K/V  BoltDB  Zookeeper  Etcd  Consul Catalog  Rancher  Marathon  Kubernetes (using a provider-specific mechanism based on label selectors)   Supported filters:   tag   # Constraints definition\n#\n# Optional\n#\n# Simple matching constraint\n# constraints = [ tag==api ]\n\n# Simple mismatching constraint\n# constraints = [ tag!=api ]\n\n# Globbing\n# constraints = [ tag==us-* ]\n\n# Multiple constraints\n#   -  tag==  must match with at least one tag\n#   -  tag!=  must match with none of tags\n# constraints = [ tag!=us-* ,  tag!=asia-* ]\n\n# Backend-specific constraint\n# [consulCatalog]\n#   endpoint = 127.0.0.1:8500\n#   constraints = [ tag==api ]\n\n# [consulCatalog]\n#   endpoint = 127.0.0.1:8500\n#   constraints = [ tag==api ,  tag!=v*-beta ]", 
            "title": "Constraints"
        }, 
        {
            "location": "/configuration/commons/#access-log-definition", 
            "text": "Access logs are written when  [accessLog]  is defined. \nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.  To enable access logs using the default settings just add the  [accessLog]  entry.  [accessLog]  To write the logs into a logfile specify the  filePath .  [accessLog]\n  filePath =  /path/to/access.log   To write JSON format logs, specify  json  as the format:  [accessLog]\n  filePath   =  /path/to/access.log \n  format     =  json", 
            "title": "Access Log Definition"
        }, 
        {
            "location": "/configuration/commons/#entry-points-definition", 
            "text": "# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "Entry Points Definition"
        }, 
        {
            "location": "/configuration/commons/#redirect-http-to-https", 
            "text": "# To redirect an http entrypoint to an https entrypoint (with SNI support):\n#\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "Redirect HTTP to HTTPS"
        }, 
        {
            "location": "/configuration/commons/#rewriting-url", 
            "text": "# To redirect an entrypoint rewriting the URL:\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      regex =  ^http://localhost/(.*) \n      replacement =  http://mydomain/$1", 
            "title": "Rewriting URL"
        }, 
        {
            "location": "/configuration/commons/#tls-mutual-authentication", 
            "text": "# Only accept clients that present a certificate signed by a specified\n# Certificate Authority (CA)\n# ClientCAFiles can be configured with multiple CA:s in the same file or\n# use multiple files containing one or several CA:s. The CA:s has to be in PEM format.\n# All clients will be required to present a valid cert.\n# The requirement will apply to all server certs in the entrypoint\n# In the example below both snitest.com and snitest.org will require client certs\n#\n[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n  ClientCAFiles = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n    [[entryPoints.https.tls.certificates]]\n    CertFile =  integration/fixtures/https/snitest.com.cert \n    KeyFile =  integration/fixtures/https/snitest.com.key \n    [[entryPoints.https.tls.certificates]]\n    CertFile =  integration/fixtures/https/snitest.org.cert \n    KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "TLS Mutual Authentication"
        }, 
        {
            "location": "/configuration/commons/#basic-digest-authentication", 
            "text": "# To enable basic auth on an entrypoint\n#\n# with 2 user/pass: test:test and test2:test2\n# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones.\n# Users can be specified directly in the toml file, or indirectly by referencing an external file;\n# if both are provided, the two are merged, with external file contents having precedence.\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\n  usersFile =  /path/to/.htpasswd   # To enable digest auth on an entrypoint\n#\n# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n# You can use htdigest to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file;\n# if both are provided, the two are merged, with external file contents having precedence\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:traefik:a2688e031edb4be6a3797f3882655c05  ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\n  usersFile =  /path/to/.htdigest", 
            "title": "Basic &amp; Digest Authentication"
        }, 
        {
            "location": "/configuration/commons/#specify-minimum-tls-version", 
            "text": "# To specify an https entrypoint with a minimum TLS version, \n# and specifying an array of cipher suites (from crypto/tls):\n[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n    MinVersion =  VersionTLS12 \n    CipherSuites = [ TLS_RSA_WITH_AES_256_GCM_SHA384 ]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "Specify Minimum TLS Version"
        }, 
        {
            "location": "/configuration/commons/#compression", 
            "text": "# To enable compression support using gzip format:\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  compress = true", 
            "title": "Compression"
        }, 
        {
            "location": "/configuration/commons/#whitelisting", 
            "text": "# To enable IP whitelisting at the entrypoint level:\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  whiteListSourceRange = [ 127.0.0.1/32 ]", 
            "title": "Whitelisting"
        }, 
        {
            "location": "/configuration/commons/#proxyprotocol-support", 
            "text": "# To enable ProxyProtocol support (https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt):\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  proxyprotocol = true", 
            "title": "ProxyProtocol Support"
        }, 
        {
            "location": "/configuration/commons/#retry-configuration", 
            "text": "# Enable retry sending request if network error\n#\n# Optional\n#\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3", 
            "title": "Retry Configuration"
        }, 
        {
            "location": "/configuration/commons/#health-check-configuration", 
            "text": "# Enable custom health check options.\n#\n# Optional\n#\n[healthcheck]\n\n# Set the default health check interval. Will only be effective if health check\n# paths are defined. Given provider-specific support, the value may be\n# overridden on a per-backend basis.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default:  30s \n#\n# interval =  30s", 
            "title": "Health Check Configuration"
        }, 
        {
            "location": "/configuration/commons/#responding-timeouts", 
            "text": "# respondingTimeouts are timeouts for incoming requests to the Traefik instance.\n#\n# Optional\n# \n[respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n# \n# Optional\n# Default:  0s \n# \n# readTimeout =  5s \n\n# writeTimeout is the maximum duration before timing out writes of the response. It covers the time from the end of \n# the request header read to the end of the response write.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  0s \n# \n# writeTimeout =  5s \n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  180s \n#\n# idleTimeout =  360s", 
            "title": "Responding Timeouts"
        }, 
        {
            "location": "/configuration/commons/#forwarding-timeouts", 
            "text": "# forwardingTimeouts are timeouts for requests forwarded to the backend servers.\n#\n# Optional\n# \n[forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established. \n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n# \n# Optional\n# Default:  30s \n# \n# dialTimeout =  30s \n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any). \n# If zero, no timeout exists.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  0s \n# \n# responseHeaderTimeout =  0s", 
            "title": "Forwarding Timeouts"
        }, 
        {
            "location": "/configuration/acme/", 
            "text": "ACME (Let's Encrypt) configuration\n\n\n# Sample entrypoint configuration when using ACME\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL\n#\n# Optional\n#\n[acme]\n\n# Email address used for registration\n#\n# Required\n#\nemail = \ntest@traefik.io\n\n\n# File or key used for certificates storage.\n# WARNING, if you use Traefik in Docker, you have 2 options:\n#  - create a file on your host and mount it as a volume\n#      storageFile = \nacme.json\n\n#      $ docker run -v \n/my/host/acme.json:acme.json\n traefik\n#  - mount the folder containing the file as a volume\n#      storageFile = \n/etc/traefik/acme/acme.json\n\n#      $ docker run -v \n/my/host/acme:/etc/traefik/acme\n traefik\n#\n# Required\n#\nstorage = \nacme.json\n # or \ntraefik/acme/account\n if using KV store\n\n# Entrypoint to proxy acme challenge/apply certificates to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint = \nhttps\n\n\n# Use a DNS based acme challenge rather than external HTTPS access, e.g. for a firewalled server\n# Select the provider that matches the DNS domain that will host the challenge TXT record,\n# and provide environment variables with access keys to enable setting it:\n#  - cloudflare: CLOUDFLARE_EMAIL, CLOUDFLARE_API_KEY\n#  - digitalocean: DO_AUTH_TOKEN\n#  - dnsimple: DNSIMPLE_EMAIL, DNSIMPLE_OAUTH_TOKEN\n#  - dnsmadeeasy: DNSMADEEASY_API_KEY, DNSMADEEASY_API_SECRET\n#  - exoscale: EXOSCALE_API_KEY, EXOSCALE_API_SECRET\n#  - gandi: GANDI_API_KEY\n#  - linode: LINODE_API_KEY\n#  - manual: none, but run traefik interactively \n turn on acmeLogging to see instructions \n press Enter\n#  - namecheap: NAMECHEAP_API_USER, NAMECHEAP_API_KEY\n#  - rfc2136: RFC2136_TSIG_KEY, RFC2136_TSIG_SECRET, RFC2136_TSIG_ALGORITHM, RFC2136_NAMESERVER\n#  - route53: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, or configured user/instance IAM profile\n#  - dyn: DYN_CUSTOMER_NAME, DYN_USER_NAME, DYN_PASSWORD\n#  - vultr: VULTR_API_KEY\n#  - ovh: OVH_ENDPOINT, OVH_APPLICATION_KEY, OVH_APPLICATION_SECRET, OVH_CONSUMER_KEY\n#  - pdns: PDNS_API_KEY, PDNS_API_URL\n#\n# Optional\n#\n# dnsProvider = \ndigitalocean\n\n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify\n# If delayDontCheckDNS is greater than zero, avoid this \n instead just wait so many seconds.\n# Useful if internal networks block external DNS queries\n#\n# Optional\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library\n#\n# Optional\n#\n# acmeLogging = true\n\n# Enable on demand certificate. This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.\n# WARNING, TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DoS attacks.\n# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n#\n# Optional\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules. This will request a certificate from Let's Encrypt for each frontend with a Host rule.\n# For example, a rule Host:test1.traefik.io,test2.traefik.io will request a certificate with main domain test1.traefik.io and SAN test2.traefik.io.\n#\n# Optional\n#\n# OnHostRule = true\n\n# CA server to use\n# Uncomment the line to run on the staging let's encrypt server\n# Leave comment to go to prod\n#\n# Optional\n#\n# caServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n\n# Domains list\n# You can provide SANs (alternative domains) to each main domain\n# All domains must have A/AAAA records pointing to Traefik\n# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n# Each domain \n SANs will lead to a certificate request.\n#\n# [[acme.domains]]\n#   main = \nlocal1.com\n\n#   sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n# [[acme.domains]]\n#   main = \nlocal2.com\n\n#   sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n# [[acme.domains]]\n#   main = \nlocal3.com\n\n# [[acme.domains]]\n#   main = \nlocal4.com\n\n[[acme.domains]]\n   main = \nlocal1.com\n\n   sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n   main = \nlocal3.com\n\n[[acme.domains]]\n   main = \nlocal4.com", 
            "title": "Let's Encrypt"
        }, 
        {
            "location": "/configuration/acme/#acme-lets-encrypt-configuration", 
            "text": "# Sample entrypoint configuration when using ACME\n[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL\n#\n# Optional\n#\n[acme]\n\n# Email address used for registration\n#\n# Required\n#\nemail =  test@traefik.io \n\n# File or key used for certificates storage.\n# WARNING, if you use Traefik in Docker, you have 2 options:\n#  - create a file on your host and mount it as a volume\n#      storageFile =  acme.json \n#      $ docker run -v  /my/host/acme.json:acme.json  traefik\n#  - mount the folder containing the file as a volume\n#      storageFile =  /etc/traefik/acme/acme.json \n#      $ docker run -v  /my/host/acme:/etc/traefik/acme  traefik\n#\n# Required\n#\nstorage =  acme.json  # or  traefik/acme/account  if using KV store\n\n# Entrypoint to proxy acme challenge/apply certificates to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint =  https \n\n# Use a DNS based acme challenge rather than external HTTPS access, e.g. for a firewalled server\n# Select the provider that matches the DNS domain that will host the challenge TXT record,\n# and provide environment variables with access keys to enable setting it:\n#  - cloudflare: CLOUDFLARE_EMAIL, CLOUDFLARE_API_KEY\n#  - digitalocean: DO_AUTH_TOKEN\n#  - dnsimple: DNSIMPLE_EMAIL, DNSIMPLE_OAUTH_TOKEN\n#  - dnsmadeeasy: DNSMADEEASY_API_KEY, DNSMADEEASY_API_SECRET\n#  - exoscale: EXOSCALE_API_KEY, EXOSCALE_API_SECRET\n#  - gandi: GANDI_API_KEY\n#  - linode: LINODE_API_KEY\n#  - manual: none, but run traefik interactively   turn on acmeLogging to see instructions   press Enter\n#  - namecheap: NAMECHEAP_API_USER, NAMECHEAP_API_KEY\n#  - rfc2136: RFC2136_TSIG_KEY, RFC2136_TSIG_SECRET, RFC2136_TSIG_ALGORITHM, RFC2136_NAMESERVER\n#  - route53: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, or configured user/instance IAM profile\n#  - dyn: DYN_CUSTOMER_NAME, DYN_USER_NAME, DYN_PASSWORD\n#  - vultr: VULTR_API_KEY\n#  - ovh: OVH_ENDPOINT, OVH_APPLICATION_KEY, OVH_APPLICATION_SECRET, OVH_CONSUMER_KEY\n#  - pdns: PDNS_API_KEY, PDNS_API_URL\n#\n# Optional\n#\n# dnsProvider =  digitalocean \n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify\n# If delayDontCheckDNS is greater than zero, avoid this   instead just wait so many seconds.\n# Useful if internal networks block external DNS queries\n#\n# Optional\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library\n#\n# Optional\n#\n# acmeLogging = true\n\n# Enable on demand certificate. This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.\n# WARNING, TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DoS attacks.\n# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n#\n# Optional\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules. This will request a certificate from Let's Encrypt for each frontend with a Host rule.\n# For example, a rule Host:test1.traefik.io,test2.traefik.io will request a certificate with main domain test1.traefik.io and SAN test2.traefik.io.\n#\n# Optional\n#\n# OnHostRule = true\n\n# CA server to use\n# Uncomment the line to run on the staging let's encrypt server\n# Leave comment to go to prod\n#\n# Optional\n#\n# caServer =  https://acme-staging.api.letsencrypt.org/directory \n\n# Domains list\n# You can provide SANs (alternative domains) to each main domain\n# All domains must have A/AAAA records pointing to Traefik\n# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n# Each domain   SANs will lead to a certificate request.\n#\n# [[acme.domains]]\n#   main =  local1.com \n#   sans = [ test1.local1.com ,  test2.local1.com ]\n# [[acme.domains]]\n#   main =  local2.com \n#   sans = [ test1.local2.com ,  test2x.local2.com ]\n# [[acme.domains]]\n#   main =  local3.com \n# [[acme.domains]]\n#   main =  local4.com \n[[acme.domains]]\n   main =  local1.com \n   sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n   main =  local3.com \n[[acme.domains]]\n   main =  local4.com", 
            "title": "ACME (Let's Encrypt) configuration"
        }, 
        {
            "location": "/configuration/backends/web/", 
            "text": "Web Backend\n\n\nTr\u00e6fik can be configured:\n\n\n\n\nusing a RESTful api.\n\n\nto use a metric system (like Prometheus, DataDog or StatD, ...).\n\n\nto expose a Web Dashboard.\n\n\n\n\nConfiguration\n\n\n[web]\n\n# Web administration port\n#\n# Required\n#\naddress = \n:8080\n\n\n# SSL certificate and key used\n#\n# Optional\n#\n# CertFile = \ntraefik.crt\n\n# KeyFile = \ntraefik.key\n\n\n# Set REST API to read-only mode\n#\n# Optional\n# ReadOnly = false\n\n# Enable more detailed statistics\n# [web.statistics]\n#   RecentErrors = 10\n\n# To enable basic auth on the webui\n# with 2 user/pass: test:test and test2:test2\n# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence\n#   [web.auth.basic]\n#     users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n#     usersFile = \n/path/to/.htpasswd\n\n# To enable digest auth on the webui\n# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n# You can use htdigest to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence\n#   [web.auth.digest]\n#     users = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05 \n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\n#     usersFile = \n/path/to/.htdigest\n\n\n\n\n\nWeb UI\n\n\n\n\n\n\nMetrics\n\n\nYou can enable Traefik to export internal metrics to different monitoring systems.\n\n\n# To enable Traefik to export internal metrics to Prometheus\n# [web.metrics.prometheus]\n#   Buckets=[0.1,0.3,1.2,5.0]\n\n# DataDog metrics exporter type \n# [web.metrics.datadog]\n#   Address = \nlocalhost:8125\n\n#   Pushinterval = \n10s\n\n\n# StatsD metrics exporter type\n# [web.metrics.statsd]\n#   Address = \nlocalhost:8125\n\n#   Pushinterval = \n10s\n\n\n\n\n\nAPI\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/\n\n\nGET\n\n\nProvides a simple HTML frontend of Tr\u00e6fik\n\n\n\n\n\n\n/ping\n\n\nGET\n, \nHEAD\n\n\nA simple endpoint to check for Tr\u00e6fik process liveness. Return a code \n200\n with the content: \nOK\n\n\n\n\n\n\n/health\n\n\nGET\n\n\njson health metrics\n\n\n\n\n\n\n/api\n\n\nGET\n\n\nConfiguration for all providers\n\n\n\n\n\n\n/api/providers\n\n\nGET\n\n\nProviders\n\n\n\n\n\n\n/api/providers/{provider}\n\n\nGET\n, \nPUT\n\n\nGet or update provider\n\n\n\n\n\n\n/api/providers/{provider}/backends\n\n\nGET\n\n\nList backends\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}\n\n\nGET\n\n\nGet backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers\n\n\nGET\n\n\nList servers in backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers/{server}\n\n\nGET\n\n\nGet a server in a backend\n\n\n\n\n\n\n/api/providers/{provider}/frontends\n\n\nGET\n\n\nList frontends\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}\n\n\nGET\n\n\nGet a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes\n\n\nGET\n\n\nList routes in a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes/{route}\n\n\nGET\n\n\nGet a route in a frontend\n\n\n\n\n\n\n/metrics\n\n\nGET\n\n\nExport internal metrics\n\n\n\n\n\n\n\n\nExample\n\n\nPing\n\n\n$ curl -sv \nhttp://localhost:8080/ping\n\n\n\n\n\n*   Trying ::1...\n* Connected to localhost (::1) port 8080 (#0)\n\n GET /ping HTTP/1.1\n\n Host: localhost:8080\n\n User-Agent: curl/7.43.0\n\n Accept: */*\n\n\n\n HTTP/1.1 200 OK\n\n Date: Thu, 25 Aug 2016 01:35:36 GMT\n\n Content-Length: 2\n\n Content-Type: text/plain; charset=utf-8\n\n\n* Connection #0 to host localhost left intact\nOK\n\n\n\n\nHealth\n\n\n$ curl -s \nhttp://localhost:8080/health\n | jq .\n\n\n\n\n{\n  // Tr\u00e6fik PID\n  \npid\n: 2458,\n  // Tr\u00e6fik server uptime (formated time)\n  \nuptime\n: \n39m6.885931127s\n,\n  //  Tr\u00e6fik server uptime in seconds\n  \nuptime_sec\n: 2346.885931127,\n  // current server date\n  \ntime\n: \n2015-10-07 18:32:24.362238909 +0200 CEST\n,\n  // current server date in seconds\n  \nunixtime\n: 1444235544,\n  // count HTTP response status code in realtime\n  \nstatus_code_count\n: {\n    \n502\n: 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n  \ntotal_status_code_count\n: {\n    \n200\n: 7,\n    \n404\n: 21,\n    \n502\n: 13\n  },\n  // count HTTP response\n  \ncount\n: 1,\n  // count HTTP response\n  \ntotal_count\n: 41,\n  // sum of all response time (formated time)\n  \ntotal_response_time\n: \n35.456865605s\n,\n  // sum of all response time in seconds\n  \ntotal_response_time_sec\n: 35.456865605,\n  // average response time (formated time)\n  \naverage_response_time\n: \n864.8016ms\n,\n  // average response time in seconds\n  \naverage_response_time_sec\n: 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n  \nrecent_errors\n: [\n    {\n      // status code\n      \nstatus_code\n: 500,\n      // description of status code\n      \nstatus\n: \nInternal Server Error\n,\n      // request HTTP method\n      \nmethod\n: \nGET\n,\n      // request hostname\n      \nhost\n: \nlocalhost\n,\n      // request path\n      \npath\n: \n/path\n,\n      // RFC 3339 formatted date/time\n      \ntime\n: \n2016-10-21T16:59:15.418495872-07:00\n\n    }\n  ]\n}\n\n\n\n\nProvider configurations\n\n\n$ curl -s \nhttp://localhost:8080/api\n | jq .\n\n\n\n\n{\n  \nfile\n: {\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Web Backend"
        }, 
        {
            "location": "/configuration/backends/web/#web-backend", 
            "text": "Tr\u00e6fik can be configured:   using a RESTful api.  to use a metric system (like Prometheus, DataDog or StatD, ...).  to expose a Web Dashboard.", 
            "title": "Web Backend"
        }, 
        {
            "location": "/configuration/backends/web/#configuration", 
            "text": "[web]\n\n# Web administration port\n#\n# Required\n#\naddress =  :8080 \n\n# SSL certificate and key used\n#\n# Optional\n#\n# CertFile =  traefik.crt \n# KeyFile =  traefik.key \n\n# Set REST API to read-only mode\n#\n# Optional\n# ReadOnly = false\n\n# Enable more detailed statistics\n# [web.statistics]\n#   RecentErrors = 10\n\n# To enable basic auth on the webui\n# with 2 user/pass: test:test and test2:test2\n# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence\n#   [web.auth.basic]\n#     users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\n#     usersFile =  /path/to/.htpasswd \n# To enable digest auth on the webui\n# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n# You can use htdigest to generate those ones\n# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence\n#   [web.auth.digest]\n#     users = [ test:traefik:a2688e031edb4be6a3797f3882655c05  ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\n#     usersFile =  /path/to/.htdigest", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/web/#web-ui", 
            "text": "", 
            "title": "Web UI"
        }, 
        {
            "location": "/configuration/backends/web/#metrics", 
            "text": "You can enable Traefik to export internal metrics to different monitoring systems.  # To enable Traefik to export internal metrics to Prometheus\n# [web.metrics.prometheus]\n#   Buckets=[0.1,0.3,1.2,5.0]\n\n# DataDog metrics exporter type \n# [web.metrics.datadog]\n#   Address =  localhost:8125 \n#   Pushinterval =  10s \n\n# StatsD metrics exporter type\n# [web.metrics.statsd]\n#   Address =  localhost:8125 \n#   Pushinterval =  10s", 
            "title": "Metrics"
        }, 
        {
            "location": "/configuration/backends/web/#api", 
            "text": "Path  Method  Description      /  GET  Provides a simple HTML frontend of Tr\u00e6fik    /ping  GET ,  HEAD  A simple endpoint to check for Tr\u00e6fik process liveness. Return a code  200  with the content:  OK    /health  GET  json health metrics    /api  GET  Configuration for all providers    /api/providers  GET  Providers    /api/providers/{provider}  GET ,  PUT  Get or update provider    /api/providers/{provider}/backends  GET  List backends    /api/providers/{provider}/backends/{backend}  GET  Get backend    /api/providers/{provider}/backends/{backend}/servers  GET  List servers in backend    /api/providers/{provider}/backends/{backend}/servers/{server}  GET  Get a server in a backend    /api/providers/{provider}/frontends  GET  List frontends    /api/providers/{provider}/frontends/{frontend}  GET  Get a frontend    /api/providers/{provider}/frontends/{frontend}/routes  GET  List routes in a frontend    /api/providers/{provider}/frontends/{frontend}/routes/{route}  GET  Get a route in a frontend    /metrics  GET  Export internal metrics", 
            "title": "API"
        }, 
        {
            "location": "/configuration/backends/web/#example", 
            "text": "", 
            "title": "Example"
        }, 
        {
            "location": "/configuration/backends/web/#ping", 
            "text": "$ curl -sv  http://localhost:8080/ping   *   Trying ::1...\n* Connected to localhost (::1) port 8080 (#0)  GET /ping HTTP/1.1  Host: localhost:8080  User-Agent: curl/7.43.0  Accept: */*   HTTP/1.1 200 OK  Date: Thu, 25 Aug 2016 01:35:36 GMT  Content-Length: 2  Content-Type: text/plain; charset=utf-8 \n* Connection #0 to host localhost left intact\nOK", 
            "title": "Ping"
        }, 
        {
            "location": "/configuration/backends/web/#health", 
            "text": "$ curl -s  http://localhost:8080/health  | jq .  {\n  // Tr\u00e6fik PID\n   pid : 2458,\n  // Tr\u00e6fik server uptime (formated time)\n   uptime :  39m6.885931127s ,\n  //  Tr\u00e6fik server uptime in seconds\n   uptime_sec : 2346.885931127,\n  // current server date\n   time :  2015-10-07 18:32:24.362238909 +0200 CEST ,\n  // current server date in seconds\n   unixtime : 1444235544,\n  // count HTTP response status code in realtime\n   status_code_count : {\n     502 : 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n   total_status_code_count : {\n     200 : 7,\n     404 : 21,\n     502 : 13\n  },\n  // count HTTP response\n   count : 1,\n  // count HTTP response\n   total_count : 41,\n  // sum of all response time (formated time)\n   total_response_time :  35.456865605s ,\n  // sum of all response time in seconds\n   total_response_time_sec : 35.456865605,\n  // average response time (formated time)\n   average_response_time :  864.8016ms ,\n  // average response time in seconds\n   average_response_time_sec : 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n   recent_errors : [\n    {\n      // status code\n       status_code : 500,\n      // description of status code\n       status :  Internal Server Error ,\n      // request HTTP method\n       method :  GET ,\n      // request hostname\n       host :  localhost ,\n      // request path\n       path :  /path ,\n      // RFC 3339 formatted date/time\n       time :  2016-10-21T16:59:15.418495872-07:00 \n    }\n  ]\n}", 
            "title": "Health"
        }, 
        {
            "location": "/configuration/backends/web/#provider-configurations", 
            "text": "$ curl -s  http://localhost:8080/api  | jq .  {\n   file : {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Provider configurations"
        }, 
        {
            "location": "/configuration/backends/boltdb/", 
            "text": "BoltDB Backend\n\n\nTr\u00e6fik can be configured to use BoltDB as a backend configuration:\n\n\n################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend\n[boltdb]\n\n# BoltDB file\n#\n# Required\n#\nendpoint = \n/my.db\n\n\n# Enable watch BoltDB changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \n/traefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\nfilename = \nboltdb.tmpl", 
            "title": "BoltDB Backend"
        }, 
        {
            "location": "/configuration/backends/boltdb/#boltdb-backend", 
            "text": "Tr\u00e6fik can be configured to use BoltDB as a backend configuration:  ################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend\n[boltdb]\n\n# BoltDB file\n#\n# Required\n#\nendpoint =  /my.db \n\n# Enable watch BoltDB changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  /traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\nfilename =  boltdb.tmpl", 
            "title": "BoltDB Backend"
        }, 
        {
            "location": "/configuration/backends/consul/", 
            "text": "Consul Backend\n\n\nConsul Key-Value backend\n\n\nTr\u00e6fik can be configured to use Consul as a backend configuration:\n\n\n################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend\n[consul]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Enable watch Consul changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \ntraefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nconsul.tmpl\n\n\n# Enable consul TLS connection\n#\n# Optional\n#\n# [consul.tls]\n# ca = \n/etc/ssl/ca.crt\n\n# cert = \n/etc/ssl/consul.crt\n\n# key = \n/etc/ssl/consul.key\n\n# insecureskipverify = true\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on traefik KV structure.\n\n\nConsul catalog backend\n\n\nTr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration:\n\n\n################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend\n[consulCatalog]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Default domain used.\n#\n# Optional\n#\ndomain = \nconsul.localhost\n\n\n# Expose Consul catalog services by default in traefik\n#\n# Optional\n#\nexposedByDefault = false\n\n# Prefix for Consul catalog tags\n#\n# Optional\n#\nprefix = \ntraefik\n\n\n# Default frontEnd Rule for Consul services\n#\n# The format is a Go Template with:\n# - \n.ServiceName\n, \n.Domain\n and \n.Attributes\n available\n# - \ngetTag(name, tags, defaultValue)\n, \nhasTag(name, tags)\n and \ngetAttribute(name, tags, defaultValue)\n functions are available\n# - \ngetAttribute(...)\n function uses prefixed tag names based on \nprefix\n value\n#\n# Optional\n#\n#frontEndRule = \nHost:{{.ServiceName}}.{{Domain}}\n\n\n\n\n\nThis backend will create routes matching on hostname based on the service name used in consul.\n\n\nAdditional settings can be defined using Consul Catalog tags:\n\n\n\n\n\n\n\n\nTag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.backend.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.backend.circuitbreaker=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend, ex: \nNetworkErrorRatio() \n 0.\n\n\n\n\n\n\ntraefik.backend.loadbalancer=drr\n\n\nOverride the default load balancing mode\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\nOverride the default frontend rule (Default: \nHost:{{.ServiceName}}.{{.Domain}}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.", 
            "title": "Consul Backend"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-backend", 
            "text": "", 
            "title": "Consul Backend"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-key-value-backend", 
            "text": "Tr\u00e6fik can be configured to use Consul as a backend configuration:  ################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend\n[consul]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:8500 \n\n# Enable watch Consul changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  consul.tmpl \n\n# Enable consul TLS connection\n#\n# Optional\n#\n# [consul.tls]\n# ca =  /etc/ssl/ca.crt \n# cert =  /etc/ssl/consul.crt \n# key =  /etc/ssl/consul.key \n# insecureskipverify = true  Please refer to the  Key Value storage structure  section to get documentation on traefik KV structure.", 
            "title": "Consul Key-Value backend"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-catalog-backend", 
            "text": "Tr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration:  ################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend\n[consulCatalog]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:8500 \n\n# Default domain used.\n#\n# Optional\n#\ndomain =  consul.localhost \n\n# Expose Consul catalog services by default in traefik\n#\n# Optional\n#\nexposedByDefault = false\n\n# Prefix for Consul catalog tags\n#\n# Optional\n#\nprefix =  traefik \n\n# Default frontEnd Rule for Consul services\n#\n# The format is a Go Template with:\n# -  .ServiceName ,  .Domain  and  .Attributes  available\n# -  getTag(name, tags, defaultValue) ,  hasTag(name, tags)  and  getAttribute(name, tags, defaultValue)  functions are available\n# -  getAttribute(...)  function uses prefixed tag names based on  prefix  value\n#\n# Optional\n#\n#frontEndRule =  Host:{{.ServiceName}}.{{Domain}}   This backend will create routes matching on hostname based on the service name used in consul.  Additional settings can be defined using Consul Catalog tags:     Tag  Description      traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.protocol=https  Override the default  http  protocol    traefik.backend.weight=10  Assign this weight to the container    traefik.backend.circuitbreaker=EXPR  Create a  circuit breaker  to be used against the backend, ex:  NetworkErrorRatio()   0.    traefik.backend.loadbalancer=drr  Override the default load balancing mode    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.frontend.rule=Host:test.traefik.io  Override the default frontend rule (Default:  Host:{{.ServiceName}}.{{.Domain}} ).    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .", 
            "title": "Consul catalog backend"
        }, 
        {
            "location": "/configuration/backends/docker/", 
            "text": "Docker Backend\n\n\nTr\u00e6fik can be configured to use Docker as a backend configuration.\n\n\nDocker\n\n\n################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint = \nunix:///var/run/docker.sock\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a container.\n#\n# Required\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose containers by default in traefik\n# If set to false, containers that don't have `traefik.enable=true` will be ignored\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one. For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection\n#\n# Optional\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nDocker Swarm Mode\n\n\n################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default: \nunix:///var/run/docker.sock\n\n#\nendpoint = \ntcp://127.0.0.1:2375\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a services.\n#\n# Optional\n# Default: \n\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider\nswarmmode = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose services by default in traefik\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection\n#\n# Optional\n#\n#  [swarm.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nLabels can be used on containers to override default behaviour\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nGive the name \nfoo\n to the generated backend for this container.\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.swarm=true\n\n\nUse Swarm's inbuilt load balancer (only relevant under Swarm Mode).\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.port=80\n\n\nRegister this port. Useful when the container exposes multiples ports.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=EXPR\n\n\nOverride the default frontend rule. Default: \nHost:{containerName}.{domain}\n or \nHost:{service}.{project_name}.{domain}\n if you are using \ndocker-compose\n.\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.frontend.whitelistSourceRange:RANGE\n\n\nList of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\n\n\n\n\ntraefik.docker.network\n\n\nSet the docker network to use for connections to this container. If a container is linked to several networks, be sure to set the proper network name (you can check with docker inspect \n) otherwise it will randomly pick one (depending on how docker is returning them). For instance when deploying docker \nstack\n from compose files, the compose defined networks will be prefixed with the \nstack\n name.\n\n\n\n\n\n\n\n\nServices labels can be used for overriding default behaviour\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=PORT\n\n\nOverrides \ntraefik.port\n. If several ports need to be exposed, the service labels could be used.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol\n\n\nOverrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight\n\n\nAssign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=BACKEND\n\n\nAssign this service frontend to \nBACKEND\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints\n\n\nOverrides \ntraefik.frontend.entrypoints\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic\n\n\nSets a Basic Auth for that frontend\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader\n\n\nOverrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority\n\n\nOverrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule\n\n\nOverrides \ntraefik.frontend.rule\n.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nwhen running inside a container, Tr\u00e6fik will need network access through:\n\n\ndocker network connect \nnetwork\n \ntraefik-container", 
            "title": "Docker Backend"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-backend", 
            "text": "Tr\u00e6fik can be configured to use Docker as a backend configuration.", 
            "title": "Docker Backend"
        }, 
        {
            "location": "/configuration/backends/docker/#docker", 
            "text": "################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint =  unix:///var/run/docker.sock \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a container.\n#\n# Required\n#\ndomain =  docker.localhost \n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose containers by default in traefik\n# If set to false, containers that don't have `traefik.enable=true` will be ignored\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one. For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection\n#\n# Optional\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true", 
            "title": "Docker"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-swarm-mode", 
            "text": "################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default:  unix:///var/run/docker.sock \n#\nendpoint =  tcp://127.0.0.1:2375 \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a services.\n#\n# Optional\n# Default:  \n#\ndomain =  docker.localhost \n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider\nswarmmode = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose services by default in traefik\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection\n#\n# Optional\n#\n#  [swarm.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true", 
            "title": "Docker Swarm Mode"
        }, 
        {
            "location": "/configuration/backends/docker/#labels-can-be-used-on-containers-to-override-default-behaviour", 
            "text": "Label  Description      traefik.backend=foo  Give the name  foo  to the generated backend for this container.    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.sticky=true  Enable backend sticky sessions    traefik.backend.loadbalancer.swarm=true  Use Swarm's inbuilt load balancer (only relevant under Swarm Mode).    traefik.backend.circuitbreaker.expression=EXPR  Create a  circuit breaker  to be used against the backend    traefik.port=80  Register this port. Useful when the container exposes multiples ports.    traefik.protocol=https  Override the default  http  protocol    traefik.weight=10  Assign this weight to the container    traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.frontend.rule=EXPR  Override the default frontend rule. Default:  Host:{containerName}.{domain}  or  Host:{service}.{project_name}.{domain}  if you are using  docker-compose .    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.frontend.whitelistSourceRange:RANGE  List of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.    traefik.docker.network  Set the docker network to use for connections to this container. If a container is linked to several networks, be sure to set the proper network name (you can check with docker inspect  ) otherwise it will randomly pick one (depending on how docker is returning them). For instance when deploying docker  stack  from compose files, the compose defined networks will be prefixed with the  stack  name.", 
            "title": "Labels can be used on containers to override default behaviour"
        }, 
        {
            "location": "/configuration/backends/docker/#services-labels-can-be-used-for-overriding-default-behaviour", 
            "text": "Label  Description      traefik. service-name .port=PORT  Overrides  traefik.port . If several ports need to be exposed, the service labels could be used.    traefik. service-name .protocol  Overrides  traefik.protocol .    traefik. service-name .weight  Assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=BACKEND  Assign this service frontend to  BACKEND . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints  Overrides  traefik.frontend.entrypoints    traefik. service-name .frontend.auth.basic  Sets a Basic Auth for that frontend    traefik. service-name .frontend.passHostHeader  Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority  Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule  Overrides  traefik.frontend.rule .      Warning  when running inside a container, Tr\u00e6fik will need network access through:  docker network connect  network   traefik-container", 
            "title": "Services labels can be used for overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/dynamodb/", 
            "text": "DynamoDB Backend\n\n\nTr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration:\n\n\n################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend\n[dynamodb]\n\n# DyanmoDB Table Name\n#\n# Optional\n#\nTableName = \ntraefik\n\n\n# Enable watch DynamoDB changes\n#\n# Optional\n#\nWatch = true\n\n# Polling interval (in seconds)\n#\n# Optional\n#\nRefreshSeconds = 15\n\n# Region to use when connecting to AWS\n#\n# Required\n#\nRegion = \nus-west-1\n\n\n# AccessKeyID to use when connecting to AWS\n#\n# Optional\n#\nAccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS\n#\n# Optional\n#\nSecretAccessKey = \n123\n\n\n# Endpoint of local dynamodb instance for testing\n#\n# Optional\n#\nEndpoint = \nhttp://localhost:8080\n\n\n\n\n\nItems in the \ndynamodb\n table must have three attributes: \n\n\n\n\nid\n (string): The id is the primary key.\n\n\nname\n(string): The name is used as the name of the frontend or backend.\n\n\nfrontend\n or \nbackend\n (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in traefik.\n    See \ntypes/types.go\n for details.\n    The presence or absence of this attribute determines its type.\n    So an item should never have both a \nfrontend\n and a \nbackend\n attribute.", 
            "title": "DynamoDB Backend"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#dynamodb-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration:  ################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend\n[dynamodb]\n\n# DyanmoDB Table Name\n#\n# Optional\n#\nTableName =  traefik \n\n# Enable watch DynamoDB changes\n#\n# Optional\n#\nWatch = true\n\n# Polling interval (in seconds)\n#\n# Optional\n#\nRefreshSeconds = 15\n\n# Region to use when connecting to AWS\n#\n# Required\n#\nRegion =  us-west-1 \n\n# AccessKeyID to use when connecting to AWS\n#\n# Optional\n#\nAccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS\n#\n# Optional\n#\nSecretAccessKey =  123 \n\n# Endpoint of local dynamodb instance for testing\n#\n# Optional\n#\nEndpoint =  http://localhost:8080   Items in the  dynamodb  table must have three attributes:    id  (string): The id is the primary key.  name (string): The name is used as the name of the frontend or backend.  frontend  or  backend  (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in traefik.\n    See  types/types.go  for details.\n    The presence or absence of this attribute determines its type.\n    So an item should never have both a  frontend  and a  backend  attribute.", 
            "title": "DynamoDB Backend"
        }, 
        {
            "location": "/configuration/backends/ecs/", 
            "text": "ECS Backend\n\n\nTr\u00e6fik can be configured to use Amazon ECS as a backend configuration:\n\n\n################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend\n[ecs]\n\n# ECS Cluster Name\n#\n# DEPRECATED - Please use Clusters\n#\nCluster = \ndefault\n\n\n# ECS Clusters Name\n#\n# Optional\n# Default: [\ndefault\n]\n#\nClusters = [\ndefault\n]\n\n# Enable watch ECS changes\n#\n# Optional\n# Default: true\n#\nWatch = true\n\n# Enable auto discover ECS clusters\n#\n# Optional\n# Default: false\n#\nAutoDiscoverClusters = false\n\n# Polling interval (in seconds)\n#\n# Optional\n# Default: 15\n#\nRefreshSeconds = 15\n\n# Expose ECS services by default in traefik\n#\n# Optional\n# Default: true\n#\nExposedByDefault = false\n\n# Region to use when connecting to AWS\n#\n# Optional\n#\nRegion = \nus-east-1\n\n\n# AccessKeyID to use when connecting to AWS\n#\n# Optional\n#\nAccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS\n#\n# Optional\n#\nSecretAccessKey = \n123\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \necs.tmpl\n\n\n\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\n\n\nIf \nAccessKeyID\n/\nSecretAccessKey\n is not given credentials will be resolved in the following order:\n\n\n\n\nFrom environment variables; \nAWS_ACCESS_KEY_ID\n, \nAWS_SECRET_ACCESS_KEY\n, and \nAWS_SESSION_TOKEN\n.\n\n\nShared credentials, determined by \nAWS_PROFILE\n and \nAWS_SHARED_CREDENTIALS_FILE\n, defaults to \ndefault\n and \n~/.aws/credentials\n.\n\n\nEC2 instance role or ECS task role\n\n\n\n\nTr\u00e6fik needs the following policy to read ECS information:\n\n\n{\n    \nVersion\n: \n2012-10-17\n,\n    \nStatement\n: [\n        {\n            \nSid\n: \nTraefik ECS read access\n,\n            \nEffect\n: \nAllow\n,\n            \nAction\n: [\n                \necs:ListClusters\n,\n                \necs:DescribeClusters\n,\n                \necs:ListTasks\n,\n                \necs:DescribeTasks\n,\n                \necs:DescribeContainerInstances\n,\n                \necs:DescribeTaskDefinition\n,\n                \nec2:DescribeInstances\n\n            ],\n            \nResource\n: [\n                \n*\n\n            ]\n        }\n    ]\n}", 
            "title": "ECS Backend"
        }, 
        {
            "location": "/configuration/backends/ecs/#ecs-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon ECS as a backend configuration:  ################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend\n[ecs]\n\n# ECS Cluster Name\n#\n# DEPRECATED - Please use Clusters\n#\nCluster =  default \n\n# ECS Clusters Name\n#\n# Optional\n# Default: [ default ]\n#\nClusters = [ default ]\n\n# Enable watch ECS changes\n#\n# Optional\n# Default: true\n#\nWatch = true\n\n# Enable auto discover ECS clusters\n#\n# Optional\n# Default: false\n#\nAutoDiscoverClusters = false\n\n# Polling interval (in seconds)\n#\n# Optional\n# Default: 15\n#\nRefreshSeconds = 15\n\n# Expose ECS services by default in traefik\n#\n# Optional\n# Default: true\n#\nExposedByDefault = false\n\n# Region to use when connecting to AWS\n#\n# Optional\n#\nRegion =  us-east-1 \n\n# AccessKeyID to use when connecting to AWS\n#\n# Optional\n#\nAccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS\n#\n# Optional\n#\nSecretAccessKey =  123 \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  ecs.tmpl   Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the container    traefik.enable=false  disable this container in Tr\u00e6fik    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .     If  AccessKeyID / SecretAccessKey  is not given credentials will be resolved in the following order:   From environment variables;  AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY , and  AWS_SESSION_TOKEN .  Shared credentials, determined by  AWS_PROFILE  and  AWS_SHARED_CREDENTIALS_FILE , defaults to  default  and  ~/.aws/credentials .  EC2 instance role or ECS task role   Tr\u00e6fik needs the following policy to read ECS information:  {\n     Version :  2012-10-17 ,\n     Statement : [\n        {\n             Sid :  Traefik ECS read access ,\n             Effect :  Allow ,\n             Action : [\n                 ecs:ListClusters ,\n                 ecs:DescribeClusters ,\n                 ecs:ListTasks ,\n                 ecs:DescribeTasks ,\n                 ecs:DescribeContainerInstances ,\n                 ecs:DescribeTaskDefinition ,\n                 ec2:DescribeInstances \n            ],\n             Resource : [\n                 * \n            ]\n        }\n    ]\n}", 
            "title": "ECS Backend"
        }, 
        {
            "location": "/configuration/backends/etcd/", 
            "text": "Etcd Backend\n\n\nTr\u00e6fik can be configured to use Etcd as a backend configuration:\n\n\n################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend\n[etcd]\n\n# Etcd server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:2379\n\n\n# Enable watch Etcd changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \n/traefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \netcd.tmpl\n\n\n# Use etcd user/pass authentication\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection\n#\n# Optional\n#\n# [etcd.tls]\n# ca = \n/etc/ssl/ca.crt\n\n# cert = \n/etc/ssl/etcd.crt\n\n# key = \n/etc/ssl/etcd.key\n\n# insecureskipverify = true\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on traefik KV structure.", 
            "title": "Etcd Backend"
        }, 
        {
            "location": "/configuration/backends/etcd/#etcd-backend", 
            "text": "Tr\u00e6fik can be configured to use Etcd as a backend configuration:  ################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend\n[etcd]\n\n# Etcd server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:2379 \n\n# Enable watch Etcd changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  /traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  etcd.tmpl \n\n# Use etcd user/pass authentication\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection\n#\n# Optional\n#\n# [etcd.tls]\n# ca =  /etc/ssl/ca.crt \n# cert =  /etc/ssl/etcd.crt \n# key =  /etc/ssl/etcd.key \n# insecureskipverify = true  Please refer to the  Key Value storage structure  section to get documentation on traefik KV structure.", 
            "title": "Etcd Backend"
        }, 
        {
            "location": "/configuration/backends/eureka/", 
            "text": "Eureka Backend\n\n\nTr\u00e6fik can be configured to use Eureka as a backend configuration:\n\n\n################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend\n[eureka]\n\n# Eureka server endpoint.\n# endpoint := \nhttp://my.eureka.server/eureka\n\n#\n# Required\n#\nendpoint = \nhttp://my.eureka.server/eureka\n\n\n# Override default configuration time between refresh\n#\n# Optional\n# default 30s\ndelay = \n1m\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \neureka.tmpl", 
            "title": "Eureka Backend"
        }, 
        {
            "location": "/configuration/backends/eureka/#eureka-backend", 
            "text": "Tr\u00e6fik can be configured to use Eureka as a backend configuration:  ################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend\n[eureka]\n\n# Eureka server endpoint.\n# endpoint :=  http://my.eureka.server/eureka \n#\n# Required\n#\nendpoint =  http://my.eureka.server/eureka \n\n# Override default configuration time between refresh\n#\n# Optional\n# default 30s\ndelay =  1m \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  eureka.tmpl", 
            "title": "Eureka Backend"
        }, 
        {
            "location": "/configuration/backends/file/", 
            "text": "File Backends\n\n\nLike any other reverse proxy, Tr\u00e6fik can be configured with a file. You have three choices:\n\n\nSimple\n\n\nAdd your configuration at the end of the global configuration file \ntraefik.toml\n:\n\n\n# traefik.toml\nlogLevel = \nDEBUG\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n\n  # restrict access to this frontend to the specified list of IPv4/IPv6 CIDR Nets\n  # an unset or empty list allows all Source-IPs to access\n  # if one of the Net-Specifications are invalid, the whole list is invalid\n  # and allows all Source-IPs to access.\n  whitelistSourceRange = [\n10.42.0.0/16\n, \n152.89.1.33/32\n, \nafed:be44::/16\n]\n\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nRules in a Separate File\n\n\nPut your rules in a separate file, for example \nrules.toml\n:\n\n\n# traefik.toml\nlogLevel = \nDEBUG\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\nfilename = \nrules.toml\n\n\n\n\n\n# rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nMultiple .toml Files\n\n\nYou could have multiple \n.toml\n files in a directory:\n\n\n[file]\ndirectory = \n/path/to/config/\n\n\n\n\n\nIf you want Tr\u00e6fik to watch file changes automatically, just add:\n\n\n[file]\nwatch = true\n\n\n\n\nThe configuration files can be also templates written using functions provided by \ngo template\n as well as functions provided by the \nsprig library\n, like this:\n\n\n[backends]\n  [backends.backend1]\n  url = \nhttp://firstserver\n\n  [backends.backend2]\n  url = \nhttp://secondserver\n\n\n{{$frontends := dict \nfrontend1\n \nbackend1\n \nfrontend2\n \nbackend2\n}}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend = \n{{$backend}}\n\n{{end}}", 
            "title": "File Backend"
        }, 
        {
            "location": "/configuration/backends/file/#file-backends", 
            "text": "Like any other reverse proxy, Tr\u00e6fik can be configured with a file. You have three choices:", 
            "title": "File Backends"
        }, 
        {
            "location": "/configuration/backends/file/#simple", 
            "text": "Add your configuration at the end of the global configuration file  traefik.toml :  # traefik.toml\nlogLevel =  DEBUG \ndefaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n      amount = 10\n      extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n\n  # restrict access to this frontend to the specified list of IPv4/IPv6 CIDR Nets\n  # an unset or empty list allows all Source-IPs to access\n  # if one of the Net-Specifications are invalid, the whole list is invalid\n  # and allows all Source-IPs to access.\n  whitelistSourceRange = [ 10.42.0.0/16 ,  152.89.1.33/32 ,  afed:be44::/16 ]\n\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test", 
            "title": "Simple"
        }, 
        {
            "location": "/configuration/backends/file/#rules-in-a-separate-file", 
            "text": "Put your rules in a separate file, for example  rules.toml :  # traefik.toml\nlogLevel =  DEBUG \n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\nfilename =  rules.toml   # rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n      amount = 10\n      extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test", 
            "title": "Rules in a Separate File"
        }, 
        {
            "location": "/configuration/backends/file/#multiple-toml-files", 
            "text": "You could have multiple  .toml  files in a directory:  [file]\ndirectory =  /path/to/config/   If you want Tr\u00e6fik to watch file changes automatically, just add:  [file]\nwatch = true  The configuration files can be also templates written using functions provided by  go template  as well as functions provided by the  sprig library , like this:  [backends]\n  [backends.backend1]\n  url =  http://firstserver \n  [backends.backend2]\n  url =  http://secondserver \n\n{{$frontends := dict  frontend1   backend1   frontend2   backend2 }}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend =  {{$backend}} \n{{end}}", 
            "title": "Multiple .toml Files"
        }, 
        {
            "location": "/configuration/backends/kubernetes/", 
            "text": "Kubernetes Ingress Backend\n\n\nTr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration:\n\n\n################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n# Enable Kubernetes Ingress configuration backend\n[kubernetes]\n\n# Kubernetes server endpoint\n#\n# When deployed as a replication controller in Kubernetes, Traefik will use\n# the environment variables KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT\n# to construct the endpoint.\n# Secure token will be found in /var/run/secrets/kubernetes.io/serviceaccount/token\n# and SSL CA cert in /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n#\n# The endpoint may be given to override the environment variable values.\n#\n# When the environment variables are not found, Traefik will try to connect to\n# the Kubernetes API server with an external-cluster client. In this case, the\n# endpoint is required. Specifically, it may be set to the URL used by\n# `kubectl proxy` to connect to a Kubernetes cluster from localhost.\n#\n# Optional for in-cluster configuration, required otherwise\n# Default: empty\n#\n# endpoint = \nhttp://localhost:8080\n\n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token = \nmy token\n\n\n# Path to the certificate authority file used for the Kubernetes client\n# configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath = \n/my/ca.crt\n\n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [\ndefault\n, \nproduction\n]\n\n# Ingress label selector to identify Ingress objects that should be processed.\n# See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors for details.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector = \nA and not B\n\n\n\n\n\nAnnotations can be used on containers to override default behaviour for the whole Ingress resource:\n\n\n\n\ntraefik.frontend.rule.type: PathPrefixStrip\n: override the default frontend rule type (Default: \nPathPrefix\n).\n\n\ntraefik.frontend.priority: 3\n: override the default frontend rule priority (Default: \nlen(Path)\n).\n\n\n\n\nAnnotations can be used on the Kubernetes service to override default behaviour:\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n: override the default \nwrr\n load balancer algorithm\n\n\ntraefik.backend.loadbalancer.sticky=true\n: enable backend sticky sessions\n\n\n\n\nYou can find here an example \ningress\n and \nreplication controller\n.\n\n\nAdditionally, an annotation can be used on Kubernetes services to set the \ncircuit breaker expression\n for a backend.\n\n\n\n\ntraefik.backend.circuitbreaker: \nexpression\n: set the circuit breaker expression for the backend (Default: nil).\n\n\n\n\nAs known from nginx when used as Kubernetes Ingress Controller, a List of IP-Ranges which are allowed to access can be configured by using an ingress annotation:\n\n\n\n\ningress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\"\n\n\n\n\nAn unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\nAuthentication\n\n\nIs possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the the key auth.\n\n\n\n\ningress.kubernetes.io/auth-type\n: \nbasic\n\n\ningress.kubernetes.io/auth-secret\n: contains the usernames and passwords with access to the paths defined in the Ingress Rule.\n\n\n\n\nThe secret must be created in the same namespace as the Ingress rule.\n\n\nLimitations:\n\n\n\n\nBasic authentication only.\n\n\nRealm not configurable; only \ntraefik\n default.\n\n\nSecret must contain only single file.", 
            "title": "Kubernetes Ingress Backend"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#kubernetes-ingress-backend", 
            "text": "Tr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration:  ################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n# Enable Kubernetes Ingress configuration backend\n[kubernetes]\n\n# Kubernetes server endpoint\n#\n# When deployed as a replication controller in Kubernetes, Traefik will use\n# the environment variables KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT\n# to construct the endpoint.\n# Secure token will be found in /var/run/secrets/kubernetes.io/serviceaccount/token\n# and SSL CA cert in /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n#\n# The endpoint may be given to override the environment variable values.\n#\n# When the environment variables are not found, Traefik will try to connect to\n# the Kubernetes API server with an external-cluster client. In this case, the\n# endpoint is required. Specifically, it may be set to the URL used by\n# `kubectl proxy` to connect to a Kubernetes cluster from localhost.\n#\n# Optional for in-cluster configuration, required otherwise\n# Default: empty\n#\n# endpoint =  http://localhost:8080 \n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token =  my token \n\n# Path to the certificate authority file used for the Kubernetes client\n# configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath =  /my/ca.crt \n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [ default ,  production ]\n\n# Ingress label selector to identify Ingress objects that should be processed.\n# See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors for details.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector =  A and not B   Annotations can be used on containers to override default behaviour for the whole Ingress resource:   traefik.frontend.rule.type: PathPrefixStrip : override the default frontend rule type (Default:  PathPrefix ).  traefik.frontend.priority: 3 : override the default frontend rule priority (Default:  len(Path) ).   Annotations can be used on the Kubernetes service to override default behaviour:   traefik.backend.loadbalancer.method=drr : override the default  wrr  load balancer algorithm  traefik.backend.loadbalancer.sticky=true : enable backend sticky sessions   You can find here an example  ingress  and  replication controller .  Additionally, an annotation can be used on Kubernetes services to set the  circuit breaker expression  for a backend.   traefik.backend.circuitbreaker:  expression : set the circuit breaker expression for the backend (Default: nil).   As known from nginx when used as Kubernetes Ingress Controller, a List of IP-Ranges which are allowed to access can be configured by using an ingress annotation:   ingress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\"   An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.", 
            "title": "Kubernetes Ingress Backend"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#authentication", 
            "text": "Is possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the the key auth.   ingress.kubernetes.io/auth-type :  basic  ingress.kubernetes.io/auth-secret : contains the usernames and passwords with access to the paths defined in the Ingress Rule.   The secret must be created in the same namespace as the Ingress rule.  Limitations:   Basic authentication only.  Realm not configurable; only  traefik  default.  Secret must contain only single file.", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/marathon/", 
            "text": "Marathon Backend\n\n\nTr\u00e6fik can be configured to use Marathon as a backend configuration:\n\n\n################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint := \nhttp://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080\n\n#\n# Required\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Marathon changes\n#\n# Optional\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an application.\n#\n# Required\n#\ndomain = \nmarathon.localhost\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nmarathon.tmpl\n\n\n# Expose Marathon apps by default in traefik\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = true\n\n# Convert Marathon groups to subdomains\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable Marathon basic authentication\n#\n# Optional\n#\n#  [marathon.basic]\n#  httpBasicAuthUser = \nfoo\n\n#  httpBasicPassword = \nbar\n\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [marathon.TLS]\n# CA = \n/etc/ssl/ca.crt\n\n# Cert = \n/etc/ssl/marathon.cert\n\n# Key = \n/etc/ssl/marathon.key\n\n# InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment, This will override the Authorization header\n#\n# Optional\n#\n# dcosToken = \nxxxxxx\n\n\n# Override DialerTimeout\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default: \n60s\n\n# dialerTimeout = \n60s\n\n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default: \n10s\n\n#\n# keepAlive = \n10s\n\n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = false\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API. Enabling the\n# following parameter causes Traefik to filter out tasks whose readiness checks\n# have not succeeded.\n# Note that the checks are only valid at deployment times. See the Marathon\n# guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = false\n\n\n\n\nLabels can be used on containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nassign the application to \nfoo\n backend\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nset a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nset the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=NetworkErrorRatio() \n 0.5\n\n\ncreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.healthcheck.path=/health\n\n\nset the Traefik health check path [default: no health checks]\n\n\n\n\n\n\ntraefik.backend.healthcheck.interval=5s\n\n\nsets a custom health check interval in Go-parseable (\ntime.ParseDuration\n) format [default: 30s]\n\n\n\n\n\n\ntraefik.portIndex=1\n\n\nregister port by index in the application's ports array. Useful when the application exposes multiple ports.\n\n\n\n\n\n\ntraefik.port=80\n\n\nregister the explicit application port value. Cannot be used alongside \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the application\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this application in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n\n\nSets basic authentication for that frontend with the usernames and passwords test:test and test2:test2, respectively\n\n\n\n\n\n\n\n\nIf several ports need to be exposed from a container, the services labels can be used:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=443\n\n\ncreate a service binding with frontend/backend using this port. Overrides \ntraefik.port\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.portIndex=1\n\n\ncreate a service binding with frontend/backend using this port index. Overrides \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol=https\n\n\nassign \nhttps\n protocol. Overrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight=10\n\n\nassign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=fooBackend\n\n\nassign this service frontend to \nfoobackend\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints=http\n\n\nassign this service entrypoints. Overrides \ntraefik.frontend.entrypoints\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n\n\nSets a Basic Auth for that frontend with the users test:test and test2:test2.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend. Overrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority=10\n\n\nassign the service frontend priority. Overrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule=Path:/foo\n\n\nassign the service frontend rule. Overrides \ntraefik.frontend.rule\n.", 
            "title": "Marathon Backend"
        }, 
        {
            "location": "/configuration/backends/marathon/#marathon-backend", 
            "text": "Tr\u00e6fik can be configured to use Marathon as a backend configuration:  ################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint :=  http://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080 \n#\n# Required\n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Marathon changes\n#\n# Optional\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an application.\n#\n# Required\n#\ndomain =  marathon.localhost \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  marathon.tmpl \n\n# Expose Marathon apps by default in traefik\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = true\n\n# Convert Marathon groups to subdomains\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable Marathon basic authentication\n#\n# Optional\n#\n#  [marathon.basic]\n#  httpBasicAuthUser =  foo \n#  httpBasicPassword =  bar \n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [marathon.TLS]\n# CA =  /etc/ssl/ca.crt \n# Cert =  /etc/ssl/marathon.cert \n# Key =  /etc/ssl/marathon.key \n# InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment, This will override the Authorization header\n#\n# Optional\n#\n# dcosToken =  xxxxxx \n\n# Override DialerTimeout\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default:  60s \n# dialerTimeout =  60s \n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits). If no units are provided, the value is parsed assuming\n# seconds.\n#\n# Optional\n# Default:  10s \n#\n# keepAlive =  10s \n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = false\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API. Enabling the\n# following parameter causes Traefik to filter out tasks whose readiness checks\n# have not succeeded.\n# Note that the checks are only valid at deployment times. See the Marathon\n# guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = false  Labels can be used on containers to override default behaviour:     Label  Description      traefik.backend=foo  assign the application to  foo  backend    traefik.backend.maxconn.amount=10  set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions    traefik.backend.circuitbreaker.expression=NetworkErrorRatio()   0.5  create a  circuit breaker  to be used against the backend    traefik.backend.healthcheck.path=/health  set the Traefik health check path [default: no health checks]    traefik.backend.healthcheck.interval=5s  sets a custom health check interval in Go-parseable ( time.ParseDuration ) format [default: 30s]    traefik.portIndex=1  register port by index in the application's ports array. Useful when the application exposes multiple ports.    traefik.port=80  register the explicit application port value. Cannot be used alongside  traefik.portIndex .    traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the application    traefik.enable=false  disable this application in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0  Sets basic authentication for that frontend with the usernames and passwords test:test and test2:test2, respectively     If several ports need to be exposed from a container, the services labels can be used:     Label  Description      traefik. service-name .port=443  create a service binding with frontend/backend using this port. Overrides  traefik.port .    traefik. service-name .portIndex=1  create a service binding with frontend/backend using this port index. Overrides  traefik.portIndex .    traefik. service-name .protocol=https  assign  https  protocol. Overrides  traefik.protocol .    traefik. service-name .weight=10  assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=fooBackend  assign this service frontend to  foobackend . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints=http  assign this service entrypoints. Overrides  traefik.frontend.entrypoints .    traefik. service-name .frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0  Sets a Basic Auth for that frontend with the users test:test and test2:test2.    traefik. service-name .frontend.passHostHeader=true  Forward client  Host  header to the backend. Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority=10  assign the service frontend priority. Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule=Path:/foo  assign the service frontend rule. Overrides  traefik.frontend.rule .", 
            "title": "Marathon Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/", 
            "text": "Rancher Backend\n\n\nTr\u00e6fik can be configured to use Rancher as a backend configuration:\n\n\n################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an service.\n#\n# Required\n#\ndomain = \nrancher.localhost\n\n\n# Enable watch Rancher changes\n#\n# Optional\n# Default: true\n#\nWatch = true\n\n# Polling interval (in seconds)\n#\n# Optional\n#\nRefreshSeconds = 15\n\n# Expose Rancher services by default in traefik\n#\n# Optional\n# Default: true\n#\nExposedByDefault = false\n\n# Filter services with unhealthy states and inactive states\n#\n# Optional\n# Default: false\n#\nEnableServiceHealthFilter = true\n\n\n\n\nRancher Metadata Service\n\n\n# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nIntervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service\n#\n# Optional\n# Default: \n/latest\n\n#\nPrefix = \n/2016-07-29\n\n\n\n\n\nRancher API\n\n\n# Enable Rancher API configuration backend\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API\n#\n# Required\nEndpoint = \nhttp://rancherserver.example.com/v1\n\n\n# AccessKey to use when connecting to the Rancher API\n#\n# Required\nAccessKey = \nXXXXXXXXXXXXXXXXXXXX\n\n\n# SecretKey to use when connecting to the Rancher API\n#\n# Required\nSecretKey = \nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n\n\n\n\n\n\nNote\n\n\nIf Traefik needs access to the Rancher API, you need to set the \nendpoint\n, \naccesskey\n and \nsecretkey\n parameters.\n\n\nTo enable traefik to fetch information about the Environment it's deployed in only, you need to create an \nEnvironment API Key\n.\nThis can be found within the API Key advanced options.\n\n\n\n\nLabels\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n\n\nSets basic authentication for that frontend with the usernames and passwords test:test and test2:test2, respectively", 
            "title": "Rancher Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-backend", 
            "text": "Tr\u00e6fik can be configured to use Rancher as a backend configuration:  ################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an service.\n#\n# Required\n#\ndomain =  rancher.localhost \n\n# Enable watch Rancher changes\n#\n# Optional\n# Default: true\n#\nWatch = true\n\n# Polling interval (in seconds)\n#\n# Optional\n#\nRefreshSeconds = 15\n\n# Expose Rancher services by default in traefik\n#\n# Optional\n# Default: true\n#\nExposedByDefault = false\n\n# Filter services with unhealthy states and inactive states\n#\n# Optional\n# Default: false\n#\nEnableServiceHealthFilter = true", 
            "title": "Rancher Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-metadata-service", 
            "text": "# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nIntervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service\n#\n# Optional\n# Default:  /latest \n#\nPrefix =  /2016-07-29", 
            "title": "Rancher Metadata Service"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-api", 
            "text": "# Enable Rancher API configuration backend\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API\n#\n# Required\nEndpoint =  http://rancherserver.example.com/v1 \n\n# AccessKey to use when connecting to the Rancher API\n#\n# Required\nAccessKey =  XXXXXXXXXXXXXXXXXXXX \n\n# SecretKey to use when connecting to the Rancher API\n#\n# Required\nSecretKey =  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx    Note  If Traefik needs access to the Rancher API, you need to set the  endpoint ,  accesskey  and  secretkey  parameters.  To enable traefik to fetch information about the Environment it's deployed in only, you need to create an  Environment API Key .\nThis can be found within the API Key advanced options.", 
            "title": "Rancher API"
        }, 
        {
            "location": "/configuration/backends/rancher/#labels", 
            "text": "Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the container    traefik.enable=false  disable this container in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/,test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0  Sets basic authentication for that frontend with the usernames and passwords test:test and test2:test2, respectively", 
            "title": "Labels"
        }, 
        {
            "location": "/configuration/backends/zookeeper/", 
            "text": "Zookeeper Backend\n\n\nTr\u00e6fik can be configured to use Zookeeper as a backend configuration:\n\n\n################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend\n[zookeeper]\n\n# Zookeeper server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:2181\n\n\n# Enable watch Zookeeper changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \ntraefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nzookeeper.tmpl\n\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on traefik KV structure.", 
            "title": "Zookeeper Backend"
        }, 
        {
            "location": "/configuration/backends/zookeeper/#zookeeper-backend", 
            "text": "Tr\u00e6fik can be configured to use Zookeeper as a backend configuration:  ################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend\n[zookeeper]\n\n# Zookeeper server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:2181 \n\n# Enable watch Zookeeper changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  zookeeper.tmpl   Please refer to the  Key Value storage structure  section to get documentation on traefik KV structure.", 
            "title": "Zookeeper Backend"
        }, 
        {
            "location": "/user-guide/examples/", 
            "text": "Examples\n\n\nYou will find here some configuration examples of Tr\u00e6fik.\n\n\nHTTP only\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nHTTP + HTTPS (with SNI)\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nNote that we can either give path to certificate file or directly the file content itself (\nlike in this TOML example\n).\n\n\nHTTP redirect on HTTPS\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nexamples/traefik.crt\n\n      KeyFile = \nexamples/traefik.key\n\n\n\n\n\nLet's Encrypt support\n\n\nBasic example\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates for the four domains \nlocal[1-4].com\n with described SANs.\nTraefik generates these certificates when it starts and it needs to be restart if new domains are added.\n\n\nOnHostRule option\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates for the four domains \nlocal[1-4].com\n.\nTraefik generates these certificates when it starts.\n\n\nIf a backend is added with a \nonHost\n rule, Traefik will automatically generate the Let's Encrypt certificate for the new domain.\n\n\nOnDemand option\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nOnDemand = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n\n\n\n\nThis configuration allows generating a Let's Encrypt certificate during the first HTTPS request on a new domain.\n\n\n\n\nNote\n\n\nThis option simplifies the configuration but :\n\n\n\n\nTLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DDoS attacks.\n\n\nLet's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n\n\n\n\nThat's why, it's better to use the \nonHostRule\n optin if possible.\n\n\n\n\nDNS challenge\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ndnsProvider = \ndigitalocean\n # DNS Provider name (cloudflare, OVH, gandi...)\ndelayDontCheckDNS = 0\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nDNS challenge needs environment variables to be executed. This variables have to be set on the machine/container which host Traefik.\nThese variables has described \nin this section\n.\n\n\nOnHostRule option and provided certificates\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nexamples/traefik.crt\n\n      KeyFile = \nexamples/traefik.key\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n\n\n\n\nTraefik will only try to generate a Let's encrypt certificate if the domain cannot be checked by the provided certificates.\n\n\nCluster mode\n\n\nPrerequisites\n\n\nBefore to use Let's Encrypt in a Traefik cluster, take a look to \nthe key-value store explanations\n and more precisely to \nthis section\n in the way to know how to migrate from a acme local storage \n(acme.json file)\n to a key-value store configuration.\n\n\nConfiguration\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n\n\n\n\nThis configuration allows to use the key \ntraefik/acme/account\n to get/set Let's Encrypt certificates content.\nThe \nconsul\n provider contains the configuration.\n\n\n\n\nNote\n\n\nIt's possible to use others key-value store providers as described \nhere\n.\n\n\n\n\nOverride entrypoints in frontends\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nEnable Basic authentication in an entrypoint\n\n\nWith two user/pass:\n\n\n\n\ntest\n:\ntest\n\n\ntest2\n:\ntest2\n\n\n\n\nPasswords are encoded in MD5: you can use htpasswd to generate those ones.\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nPass Authenticated user to application via headers\n\n\nProviding an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth]\n    headerField = \nX-WebAuth-User\n\n    [entryPoints.http.auth.basic]\n    users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nOverride the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly\n\n\nIdleTimeout = \n360s\n\nProvidersThrottleDuration = \n5s", 
            "title": "Configuration Examples"
        }, 
        {
            "location": "/user-guide/examples/#examples", 
            "text": "You will find here some configuration examples of Tr\u00e6fik.", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/examples/#http-only", 
            "text": "defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "HTTP only"
        }, 
        {
            "location": "/user-guide/examples/#http-https-with-sni", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key   Note that we can either give path to certificate file or directly the file content itself ( like in this TOML example ).", 
            "title": "HTTP + HTTPS (with SNI)"
        }, 
        {
            "location": "/user-guide/examples/#http-redirect-on-https", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  examples/traefik.crt \n      KeyFile =  examples/traefik.key", 
            "title": "HTTP redirect on HTTPS"
        }, 
        {
            "location": "/user-guide/examples/#lets-encrypt-support", 
            "text": "", 
            "title": "Let's Encrypt support"
        }, 
        {
            "location": "/user-guide/examples/#basic-example", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates for the four domains  local[1-4].com  with described SANs.\nTraefik generates these certificates when it starts and it needs to be restart if new domains are added.", 
            "title": "Basic example"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates for the four domains  local[1-4].com .\nTraefik generates these certificates when it starts.  If a backend is added with a  onHost  rule, Traefik will automatically generate the Let's Encrypt certificate for the new domain.", 
            "title": "OnHostRule option"
        }, 
        {
            "location": "/user-guide/examples/#ondemand-option", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nOnDemand = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https   This configuration allows generating a Let's Encrypt certificate during the first HTTPS request on a new domain.   Note  This option simplifies the configuration but :   TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DDoS attacks.  Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits   That's why, it's better to use the  onHostRule  optin if possible.", 
            "title": "OnDemand option"
        }, 
        {
            "location": "/user-guide/examples/#dns-challenge", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ndnsProvider =  digitalocean  # DNS Provider name (cloudflare, OVH, gandi...)\ndelayDontCheckDNS = 0\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   DNS challenge needs environment variables to be executed. This variables have to be set on the machine/container which host Traefik.\nThese variables has described  in this section .", 
            "title": "DNS challenge"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option-and-provided-certificates", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  examples/traefik.crt \n      KeyFile =  examples/traefik.key \n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https   Traefik will only try to generate a Let's encrypt certificate if the domain cannot be checked by the provided certificates.", 
            "title": "OnHostRule option and provided certificates"
        }, 
        {
            "location": "/user-guide/examples/#cluster-mode", 
            "text": "", 
            "title": "Cluster mode"
        }, 
        {
            "location": "/user-guide/examples/#prerequisites", 
            "text": "Before to use Let's Encrypt in a Traefik cluster, take a look to  the key-value store explanations  and more precisely to  this section  in the way to know how to migrate from a acme local storage  (acme.json file)  to a key-value store configuration.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/examples/#configuration", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com \n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik   This configuration allows to use the key  traefik/acme/account  to get/set Let's Encrypt certificates content.\nThe  consul  provider contains the configuration.   Note  It's possible to use others key-value store providers as described  here .", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/examples/#override-entrypoints-in-frontends", 
            "text": "[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test", 
            "title": "Override entrypoints in frontends"
        }, 
        {
            "location": "/user-guide/examples/#enable-basic-authentication-in-an-entrypoint", 
            "text": "With two user/pass:   test : test  test2 : test2   Passwords are encoded in MD5: you can use htpasswd to generate those ones.  defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Enable Basic authentication in an entrypoint"
        }, 
        {
            "location": "/user-guide/examples/#pass-authenticated-user-to-application-via-headers", 
            "text": "Providing an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value  defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth]\n    headerField =  X-WebAuth-User \n    [entryPoints.http.auth.basic]\n    users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Pass Authenticated user to application via headers"
        }, 
        {
            "location": "/user-guide/examples/#override-the-traefik-http-server-idletimeout-andor-throttle-configurations-from-re-loading-too-quickly", 
            "text": "IdleTimeout =  360s \nProvidersThrottleDuration =  5s", 
            "title": "Override the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly"
        }, 
        {
            "location": "/user-guide/swarm/", 
            "text": "Swarm cluster\n\n\nThis section explains how to create a multi-host \nswarm\n cluster using \ndocker-machine\n and how to deploy Tr\u00e6fik on it.\nThe cluster consists of:\n\n\n\n\n2 servers\n\n\n1 swarm master\n\n\n2 swarm nodes\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou need to install \ndocker-machine\n\n\nYou need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nWe first follow \nthis guide\n to create the cluster.\n\n\nCreate machine \nmh-keystore\n\n\nThis machine is the service registry of our cluster.\n\n\ndocker-machine create -d virtualbox mh-keystore\n\n\n\n\nThen we install the service registry \nConsul\n on this machine:\n\n\neval \n$(docker-machine env mh-keystore)\n\ndocker run -d \\\n    -p \n8500:8500\n \\\n    -h \nconsul\n \\\n    progrium/consul -server -bootstrap\n\n\n\n\nCreate machine \nmhs-demo0\n\n\nThis machine is a swarm master and a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo0\n\n\n\n\nCreate machine \nmhs-demo1\n\n\nThis machine have a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo1\n\n\n\n\nCreate the overlay Network\n\n\nCreate the overlay network on the swarm master:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nDeploy Tr\u00e6fik:\n\n\ndocker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --web\n\n\n\n\nLet's explain this command:\n\n\n\n\n-p 80:80 -p 8080:8080\n: we bind ports 80 and 8080\n\n\n--net=my-net\n: run the container on the network my-net\n\n\n-v /var/lib/boot2docker/:/ssl\n: mount the ssl keys generated by docker-machine\n\n\n-c /dev/null\n: empty config file\n\n\n--docker\n: enable docker backend\n\n\n--docker.endpoint=tcp://172.18.0.1:3376\n: connect to the swarm master using the docker_gwbridge network\n\n\n--docker.tls\n: enable TLS using the docker-machine keys\n\n\n--web\n: activate the webUI on port 8080\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in GO, on the network \nmy-net\n:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env=\nconstraint:node==mhs-demo0\n emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env=\nconstraint:node==mhs-demo1\n emilevauge/whoami\n\n\n\n\nCheck that everything is started:\n\n\ndocker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami   \n/whoamI\n                8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami   \n/whoamI\n                19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik             \n/traefik -l DEBUG -c\n   36 seconds ago      Up 37 seconds       192.168.99.101:80-\n80/tcp, 192.168.99.101:8080-\n8080/tcp   mhs-demo0/serene_bhabha\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Swarm Cluster"
        }, 
        {
            "location": "/user-guide/swarm/#swarm-cluster", 
            "text": "This section explains how to create a multi-host  swarm  cluster using  docker-machine  and how to deploy Tr\u00e6fik on it.\nThe cluster consists of:   2 servers  1 swarm master  2 swarm nodes  1  overlay  network (multi-host networking)", 
            "title": "Swarm cluster"
        }, 
        {
            "location": "/user-guide/swarm/#prerequisites", 
            "text": "You need to install  docker-machine  You need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm/#cluster-provisioning", 
            "text": "We first follow  this guide  to create the cluster.", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mh-keystore", 
            "text": "This machine is the service registry of our cluster.  docker-machine create -d virtualbox mh-keystore  Then we install the service registry  Consul  on this machine:  eval  $(docker-machine env mh-keystore) \ndocker run -d \\\n    -p  8500:8500  \\\n    -h  consul  \\\n    progrium/consul -server -bootstrap", 
            "title": "Create machine mh-keystore"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo0", 
            "text": "This machine is a swarm master and a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo0", 
            "title": "Create machine mhs-demo0"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo1", 
            "text": "This machine have a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo1", 
            "title": "Create machine mhs-demo1"
        }, 
        {
            "location": "/user-guide/swarm/#create-the-overlay-network", 
            "text": "Create the overlay network on the swarm master:  eval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net", 
            "title": "Create the overlay Network"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-trfik", 
            "text": "Deploy Tr\u00e6fik:  docker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --web  Let's explain this command:   -p 80:80 -p 8080:8080 : we bind ports 80 and 8080  --net=my-net : run the container on the network my-net  -v /var/lib/boot2docker/:/ssl : mount the ssl keys generated by docker-machine  -c /dev/null : empty config file  --docker : enable docker backend  --docker.endpoint=tcp://172.18.0.1:3376 : connect to the swarm master using the docker_gwbridge network  --docker.tls : enable TLS using the docker-machine keys  --web : activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in GO, on the network  my-net :  eval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env= constraint:node==mhs-demo0  emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env= constraint:node==mhs-demo1  emilevauge/whoami  Check that everything is started:  docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami    /whoamI                 8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami    /whoamI                 19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik              /traefik -l DEBUG -c    36 seconds ago      Up 37 seconds       192.168.99.101:80- 80/tcp, 192.168.99.101:8080- 8080/tcp   mhs-demo0/serene_bhabha", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/", 
            "text": "Docker Swarm (mode) cluster\n\n\nThis section explains how to create a multi-host docker cluster with\nswarm mode using \ndocker-machine\n and\nhow to deploy Tr\u00e6fik on it.\n\n\nThe cluster consists of:\n\n\n\n\n3 servers\n\n\n1 manager\n\n\n2 workers\n\n\n1 \noverlay\n network\n(multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou will need to install \ndocker-machine\n\n\nYou will need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nFirst, let's create all the required nodes. It's a shorter version of\nthe \nswarm tutorial\n.\n\n\ndocker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2\n\n\n\n\nThen, let's setup the cluster, in order :\n\n\n\n\ninitialize the cluster\n\n\nget the token for other host to join\n\n\non both workers, join the cluster with the token\n\n\n\n\ndocker-machine ssh manager \ndocker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager)\n\n\nexport worker_token=$(docker-machine ssh manager \ndocker swarm \\\njoin-token worker -q\n)\n\ndocker-machine ssh worker1 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager)\n\n\ndocker-machine ssh worker2 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)\n\n\n\n\n\nLet's validate the cluster is up and running.\n\n\ndocker-machine ssh manager docker node ls\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n2a770ov9vixeadep674265u1n    worker1   Ready   Active\ndbi3or4q8ii8elbws70g4hkdh *  manager   Ready   Active        Leader\nesbhhy6vnqv90xomjaomdgy46    worker2   Ready   Active\n\n\n\n\nFinally, let's create a network for Tr\u00e6fik to use.\n\n\ndocker-machine ssh manager \ndocker network create --driver=overlay traefik-net\n\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nLet's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node \u2014 we are going to use a\n\nconstraint\n for that.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --web\n\n\n\n\n\nLet's explain this command:\n\n\n\n\n--publish 80:80 --publish 8080:8080\n: we publish port \n80\n and \n8080\n on the cluster.\n\n\n--constraint=node.role==manager\n: we ask docker to schedule Tr\u00e6fik on a manager node.\n\n\n--mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n:\n  we bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.\n\n\n--network traefik-net\n: we attach the Tr\u00e6fik service (and thus the underlying container) to the \ntraefik-net\n network.\n\n\n--docker\n: enable docker backend, and \n--docker.swarmmode\n to enable the swarm mode on Tr\u00e6fik.\n\n\n--web\n: activate the webUI on port 8080\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in Go. We start 2 services, on the \ntraefik-net\n network.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami\n\n\n\n\n\nNote that we set whoami1 to use sticky sessions (\n--label traefik.backend.loadbalancer.sticky=true\n).  We'll demonstrate that later.\n\n\nNote\n: If using \ndocker stack deploy\n, there is \na specific way that the labels must be defined in the docker-compose file\n.\n\n\nCheck that everything is scheduled and started:\n\n\ndocker-machine ssh manager \ndocker service ls\n\nID            NAME     REPLICAS  IMAGE              COMMAND\nab046gpaqtln  whoami0  1/1       emilevauge/whoami\ncgfg5ifzrpgm  whoami1  1/1       emilevauge/whoami\ndtpl249tfghc  traefik  1/1       traefik            --docker --docker.swarmmode --docker.domain=traefik --docker.watch --web\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip manager)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\nNote that as Tr\u00e6fik is published, you can access it from any machine and not only the manager.\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip worker1)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip worker2)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\nScale both services\n\n\ndocker-machine ssh manager \ndocker service scale whoami0=5\n\n\ndocker-machine ssh manager \ndocker service scale whoami1=5\n\n\n\n\n\nCheck that we now have 5 replicas of each \nwhoami\n service:\n\n\ndocker-machine ssh manager \ndocker service ls\n\nID            NAME     REPLICAS  IMAGE              COMMAND\nab046gpaqtln  whoami0  5/5       emilevauge/whoami\ncgfg5ifzrpgm  whoami1  5/5       emilevauge/whoami\ndtpl249tfghc  traefik  1/1       traefik            --docker --docker.swarmmode --docker.domain=traefik --docker.watch --web\n\n\n\n\nAccess to your whoami0 through Tr\u00e6fik multiple times.\n\n\nRepeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\nDo the same against whoami1:\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip manager)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\nWait, I thought we added the sticky flag to whoami1?  Traefik relies on a cookie to maintain stickyness so you'll need to test this with a browser.\n\n\nFirst you need to add whoami1.traefik to your hosts file:\n\n\nif [ -n \n$(grep whoami1.traefik /etc/hosts)\n ];  \nthen \necho \nwhoami1.traefik already exists (make sure the ip is current)\n; \nelse \nsudo -- sh -c -e \necho '$(docker-machine ip manager)\\twhoami1.traefik' \n\n /etc/hosts\n; \nfi\n\n\n\n\nNow open your browser and go to http://whoami1.traefik/\n\n\nYou will now see that stickyness is maintained.", 
            "title": "Swarm Mode Cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#docker-swarm-mode-cluster", 
            "text": "This section explains how to create a multi-host docker cluster with\nswarm mode using  docker-machine  and\nhow to deploy Tr\u00e6fik on it.  The cluster consists of:   3 servers  1 manager  2 workers  1  overlay  network\n(multi-host networking)", 
            "title": "Docker Swarm (mode) cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#prerequisites", 
            "text": "You will need to install  docker-machine  You will need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm-mode/#cluster-provisioning", 
            "text": "First, let's create all the required nodes. It's a shorter version of\nthe  swarm tutorial .  docker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2  Then, let's setup the cluster, in order :   initialize the cluster  get the token for other host to join  on both workers, join the cluster with the token   docker-machine ssh manager  docker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager) \n\nexport worker_token=$(docker-machine ssh manager  docker swarm \\\njoin-token worker -q )\n\ndocker-machine ssh worker1  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager) \n\ndocker-machine ssh worker2  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)   Let's validate the cluster is up and running.  docker-machine ssh manager docker node ls\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n2a770ov9vixeadep674265u1n    worker1   Ready   Active\ndbi3or4q8ii8elbws70g4hkdh *  manager   Ready   Active        Leader\nesbhhy6vnqv90xomjaomdgy46    worker2   Ready   Active  Finally, let's create a network for Tr\u00e6fik to use.  docker-machine ssh manager  docker network create --driver=overlay traefik-net", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-trfik", 
            "text": "Let's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node \u2014 we are going to use a constraint  for that.  docker-machine ssh manager  docker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --web   Let's explain this command:   --publish 80:80 --publish 8080:8080 : we publish port  80  and  8080  on the cluster.  --constraint=node.role==manager : we ask docker to schedule Tr\u00e6fik on a manager node.  --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock :\n  we bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.  --network traefik-net : we attach the Tr\u00e6fik service (and thus the underlying container) to the  traefik-net  network.  --docker : enable docker backend, and  --docker.swarmmode  to enable the swarm mode on Tr\u00e6fik.  --web : activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in Go. We start 2 services, on the  traefik-net  network.  docker-machine ssh manager  docker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami \n\ndocker-machine ssh manager  docker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami   Note that we set whoami1 to use sticky sessions ( --label traefik.backend.loadbalancer.sticky=true ).  We'll demonstrate that later.  Note : If using  docker stack deploy , there is  a specific way that the labels must be defined in the docker-compose file .  Check that everything is scheduled and started:  docker-machine ssh manager  docker service ls \nID            NAME     REPLICAS  IMAGE              COMMAND\nab046gpaqtln  whoami0  1/1       emilevauge/whoami\ncgfg5ifzrpgm  whoami1  1/1       emilevauge/whoami\ndtpl249tfghc  traefik  1/1       traefik            --docker --docker.swarmmode --docker.domain=traefik --docker.watch --web", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip manager)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip manager)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c  Note that as Tr\u00e6fik is published, you can access it from any machine and not only the manager.  curl -H Host:whoami0.traefik http://$(docker-machine ip worker1)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip worker2)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#scale-both-services", 
            "text": "docker-machine ssh manager  docker service scale whoami0=5 \n\ndocker-machine ssh manager  docker service scale whoami1=5   Check that we now have 5 replicas of each  whoami  service:  docker-machine ssh manager  docker service ls \nID            NAME     REPLICAS  IMAGE              COMMAND\nab046gpaqtln  whoami0  5/5       emilevauge/whoami\ncgfg5ifzrpgm  whoami1  5/5       emilevauge/whoami\ndtpl249tfghc  traefik  1/1       traefik            --docker --docker.swarmmode --docker.domain=traefik --docker.watch --web", 
            "title": "Scale both services"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-whoami0-through-trfik-multiple-times", 
            "text": "Repeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:  curl -H Host:whoami0.traefik http://$(docker-machine ip manager)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c  Do the same against whoami1:  curl -H Host:whoami1.traefik http://$(docker-machine ip manager)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c  Wait, I thought we added the sticky flag to whoami1?  Traefik relies on a cookie to maintain stickyness so you'll need to test this with a browser.  First you need to add whoami1.traefik to your hosts file:  if [ -n  $(grep whoami1.traefik /etc/hosts)  ];  \nthen \necho  whoami1.traefik already exists (make sure the ip is current) ; \nelse \nsudo -- sh -c -e  echo '$(docker-machine ip manager)\\twhoami1.traefik'   /etc/hosts ; \nfi  Now open your browser and go to http://whoami1.traefik/  You will now see that stickyness is maintained.", 
            "title": "Access to your whoami0 through Tr\u00e6fik multiple times."
        }, 
        {
            "location": "/user-guide/kubernetes/", 
            "text": "Kubernetes Ingress Controller\n\n\nThis guide explains how to use Tr\u00e6fik as an Ingress controller in a Kubernetes cluster.\nIf you are not familiar with Ingresses in Kubernetes you might want to read the \nKubernetes user guide\n\n\nThe config files used in this guide can be found in the \nexamples directory\n\n\nPrerequisites\n\n\n\n\n\n\nA working Kubernetes cluster. If you want to follow along with this guide, you should setup \nminikube\n\non your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.\n\n\n\n\n\n\nThe \nkubectl\n binary should be \ninstalled on your workstation\n.\n\n\n\n\n\n\nRole Based Access Control configuration (Kubernetes 1.6+ only)\n\n\nKubernetes introduces \nRole Based Access Control (RBAC)\n in 1.6+ to allow fine-grained control of Kubernetes resources and api.\n\n\nIf your cluster is configured with RBAC, you may need to authorize Tr\u00e6fik to use the Kubernetes API using ClusterRole and ClusterRoleBinding resources:\n\n\n\n\nNote\n\n\nyour cluster may have suitable ClusterRoles already setup, but the following should work everywhere\n\n\n\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      - \n\n    resources:\n      - pods\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system\n\n\n\n\nexamples/k8s/traefik-rbac.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml\n\n\n\n\nDeploy Tr\u00e6fik using a Deployment or DaemonSet\n\n\nIt is possible to use Tr\u00e6fik with a \nDeployment\n or a \nDaemonSet\n object,\n whereas both options have their own pros and cons:\n The scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.\nIt is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.\nOn the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a \nService\n object with a Deployment.\n\n\nThe Deployment objects looks like this:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 8080\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-deployment.yaml\n\n\n\n\nThe Service will expose two NodePorts which allow access to the ingress and the web interface.\n\n\n\n\nThe DaemonSet objects looks not much different:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - -d\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 8080\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-ds.yaml\n\n\nTo deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with \nkubectl\n:\n\n\n$ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml\n\n\n\n\n$ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml\n\n\n\n\nThere are some significant differences between using Deployments and DaemonSets.\nThe Deployment has easier up and down scaling possibilities. It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\nAt least one Pod is needed to run the Deployment.\nThe DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\nRolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.\n\n\nCheck the Pods\n\n\nNow lets check if our command was successful.\n\n\nStart by listing the pods in the \nkube-system\n namespace:\n\n\n$ kubectl --namespace=kube-system get pods\n\nNAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m\n\n\n\n\nYou should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running.\n\nIt might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.\n\n\n\n\nYou could also check the deployment with the Kubernetes dashboard, run\n\nminikube dashboard\n to open it in your browser, then choose the \nkube-system\n\nnamespace from the menu at the top right of the screen.\n\n\n\n\nYou should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:\n\n\ncurl $(minikube ip)\n404 page not found\n\n\n\n\nIf you decided to use the deployment, then you need to target the correct NodePort, which can be seen then you execute \nkubectl get services --namespace=kube-system\n.\n\n\ncurl $(minikube ip):\nNODEPORT\n\n404 page not found\n\n\n\n\n\n\nWe expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.\n\n\n\n\nDeploy Tr\u00e6fik using Helm Chart\n\n\nInstead of installing Tr\u00e6fik via an own object, you can also use the Tr\u00e6fik Helm chart.\nThis allows more complex configuration via Kubernetes \nConfigMap\n and enabled TLS certificates.\n\n\nInstall Tr\u00e6fik chart by:\n\n\n$ helm install stable/traefik\n\n\n\n\nFor more information, check out \nthe doc\n.\n\n\nSubmitting An Ingress to the cluster.\n\n\nLets start by creating a Service and an Ingress that will expose the \nTr\u00e6fik Web UI\n.\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80\n\n\n\n\nexamples/k8s/ui.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml\n\n\n\n\nNow lets setup an entry in our /etc/hosts file to route \ntraefik-ui.minikube\n to our cluster.\n\n\n\n\nIn production you would want to set up real dns entries.\n\n\nYou can get the ip address of your minikube instance by running \nminikube ip\n\n\n\n\necho \n$(minikube ip) traefik-ui.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nWe should now be able to visit \ntraefik-ui.minikube\n in the browser and view the Tr\u00e6fik Web UI.\n\n\nName based routing\n\n\nIn this example we are going to setup websites for 3 of the United Kingdoms best loved cheeses, Cheddar, Stilton and Wensleydale.\n\n\nFirst lets start by launching the 3 pods for the cheese websites.\n\n\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80\n\n\n\n\nexamples/k8s/cheese-deployments.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml\n\n\n\n\nNext we need to setup a service for each of the cheese pods.\n\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker: \nNetworkErrorRatio() \n 0.5\n\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale\n\n\n\n\n\n\nNotice that we also set a \ncircuit breaker expression\n for one of the backends\nby setting the \ntraefik.backend.circuitbreaker\n annotation on the service.\n\n\n\n\nexamples/k8s/cheese-services.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml\n\n\n\n\nNow we can submit an ingress for the cheese websites.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheese-ingress.yaml\n\n\n\n\nNotice that we list each hostname, and add a backend service.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml\n\n\n\n\nNow visit the \nTr\u00e6fik dashboard\n and you should see a frontend for each host. Along with a backend listing for each service with a Server set up for each pod.\n\n\nIf you edit your \n/etc/hosts\n again you should be able to access the cheese websites in your browser.\n\n\necho \n$(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\n\n\nStilton\n\n\nCheddar\n\n\nWensleydale\n\n\n\n\nPath based routing\n\n\nNow lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.\n\n\nNo problem, we say, why don't we reconfigure the sites to host all 3 under one domain.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheeses-ingress.yaml\n\n\n\n\nNotice that we are configuring Tr\u00e6fik to strip the prefix from the url path\nwith the \ntraefik.frontend.rule.type\n annotation so that we can use\nthe containers from the previous example without modification.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml\n\n\n\n\necho \n$(minikube ip) cheeses.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nYou should now be able to visit the websites in your browser.\n\n\n\n\ncheeses.minikube/stilton\n\n\ncheeses.minikube/cheddar\n\n\ncheeses.minikube/wensleydale\n\n\n\n\nSpecifying priority for routing\n\n\nSometimes you need to specify priority for ingress route, especially when handling wildcard routes.\nThis can be done by adding annotation \ntraefik.frontend.priority\n, i.e.:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority: 1\nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority: 2\nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\n\n\n\nForwarding to ExternalNames\n\n\nWhen specifying an \nExternalName\n,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443.\nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.\n\n\nDisable passing the Host header\n\n\nBy default Tr\u00e6fik will pass the incoming Host header on to the upstream resource.\nThere are times however where you may not want this to be the case.\nFor example if your service is of the ExternalName type.\n\n\nDisable entirely\n\n\nAdd the following to your toml config:\n\n\ndisablePassHostHeaders = true\n\n\n\n\nDisable per ingress\n\n\nTo disable passing the Host header per ingress resource set the \ntraefik.frontend.passHostHeader\n annotation on your ingress to \nfalse\n.\n\n\nHere is an example ingress definition:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader: \nfalse\n\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https\n\n\n\n\nAnd an example service definition:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com\n\n\n\n\nIf you were to visit \nexample.com/static\n the request would then be passed onto \nstatic.otherdomain.com/static\n and s\ntatic.otherdomain.com\n would receive the request with the Host header being \nstatic.otherdomain.com\n.\n\n\n\n\nNote\n\n\nThe per ingress annotation overides whatever the global value is set to.\nSo you could set \ndisablePassHostHeaders\n to \ntrue\n in your toml file and then enable passing \nthe host header per ingress if you wanted.\n\n\n\n\nExcluding an ingress from Tr\u00e6fik\n\n\nYou can control which ingress Tr\u00e6fik cares about by using the \nkubernetes.io/ingress.class\n annotation.\nBy default if the annotation is not set at all Tr\u00e6fik will include the ingress.\nIf the annotation is set to anything other than traefik or a blank string Tr\u00e6fik will ignore it.", 
            "title": "Kubernetes"
        }, 
        {
            "location": "/user-guide/kubernetes/#kubernetes-ingress-controller", 
            "text": "This guide explains how to use Tr\u00e6fik as an Ingress controller in a Kubernetes cluster.\nIf you are not familiar with Ingresses in Kubernetes you might want to read the  Kubernetes user guide  The config files used in this guide can be found in the  examples directory", 
            "title": "Kubernetes Ingress Controller"
        }, 
        {
            "location": "/user-guide/kubernetes/#prerequisites", 
            "text": "A working Kubernetes cluster. If you want to follow along with this guide, you should setup  minikube \non your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.    The  kubectl  binary should be  installed on your workstation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/kubernetes/#role-based-access-control-configuration-kubernetes-16-only", 
            "text": "Kubernetes introduces  Role Based Access Control (RBAC)  in 1.6+ to allow fine-grained control of Kubernetes resources and api.  If your cluster is configured with RBAC, you may need to authorize Tr\u00e6fik to use the Kubernetes API using ClusterRole and ClusterRoleBinding resources:   Note  your cluster may have suitable ClusterRoles already setup, but the following should work everywhere   ---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      -  \n    resources:\n      - pods\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system  examples/k8s/traefik-rbac.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml", 
            "title": "Role Based Access Control configuration (Kubernetes 1.6+ only)"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-a-deployment-or-daemonset", 
            "text": "It is possible to use Tr\u00e6fik with a  Deployment  or a  DaemonSet  object,\n whereas both options have their own pros and cons:\n The scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.\nIt is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.\nOn the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a  Service  object with a Deployment.  The Deployment objects looks like this:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 8080\n  type: NodePort  examples/k8s/traefik-deployment.yaml   The Service will expose two NodePorts which allow access to the ingress and the web interface.   The DaemonSet objects looks not much different:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - -d\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 8080\n  type: NodePort  examples/k8s/traefik-ds.yaml  To deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with  kubectl :  $ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml  $ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml  There are some significant differences between using Deployments and DaemonSets.\nThe Deployment has easier up and down scaling possibilities. It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\nAt least one Pod is needed to run the Deployment.\nThe DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\nRolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.", 
            "title": "Deploy Tr\u00e6fik using a Deployment or DaemonSet"
        }, 
        {
            "location": "/user-guide/kubernetes/#check-the-pods", 
            "text": "Now lets check if our command was successful.  Start by listing the pods in the  kube-system  namespace:  $ kubectl --namespace=kube-system get pods\n\nNAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m  You should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running. It might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.   You could also check the deployment with the Kubernetes dashboard, run minikube dashboard  to open it in your browser, then choose the  kube-system \nnamespace from the menu at the top right of the screen.   You should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:  curl $(minikube ip)\n404 page not found  If you decided to use the deployment, then you need to target the correct NodePort, which can be seen then you execute  kubectl get services --namespace=kube-system .  curl $(minikube ip): NODEPORT \n404 page not found   We expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.", 
            "title": "Check the Pods"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-helm-chart", 
            "text": "Instead of installing Tr\u00e6fik via an own object, you can also use the Tr\u00e6fik Helm chart.\nThis allows more complex configuration via Kubernetes  ConfigMap  and enabled TLS certificates.  Install Tr\u00e6fik chart by:  $ helm install stable/traefik  For more information, check out  the doc .", 
            "title": "Deploy Tr\u00e6fik using Helm Chart"
        }, 
        {
            "location": "/user-guide/kubernetes/#submitting-an-ingress-to-the-cluster", 
            "text": "Lets start by creating a Service and an Ingress that will expose the  Tr\u00e6fik Web UI .  apiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80  examples/k8s/ui.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml  Now lets setup an entry in our /etc/hosts file to route  traefik-ui.minikube  to our cluster.   In production you would want to set up real dns entries.  You can get the ip address of your minikube instance by running  minikube ip   echo  $(minikube ip) traefik-ui.minikube  | sudo tee -a /etc/hosts  We should now be able to visit  traefik-ui.minikube  in the browser and view the Tr\u00e6fik Web UI.", 
            "title": "Submitting An Ingress to the cluster."
        }, 
        {
            "location": "/user-guide/kubernetes/#name-based-routing", 
            "text": "In this example we are going to setup websites for 3 of the United Kingdoms best loved cheeses, Cheddar, Stilton and Wensleydale.  First lets start by launching the 3 pods for the cheese websites.  ---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        resources:\n          requests:\n            cpu: 100m\n            memory: 50Mi\n          limits:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 80  examples/k8s/cheese-deployments.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml  Next we need to setup a service for each of the cheese pods.  ---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker:  NetworkErrorRatio()   0.5 \nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale   Notice that we also set a  circuit breaker expression  for one of the backends\nby setting the  traefik.backend.circuitbreaker  annotation on the service.   examples/k8s/cheese-services.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml  Now we can submit an ingress for the cheese websites.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheese-ingress.yaml   Notice that we list each hostname, and add a backend service.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml  Now visit the  Tr\u00e6fik dashboard  and you should see a frontend for each host. Along with a backend listing for each service with a Server set up for each pod.  If you edit your  /etc/hosts  again you should be able to access the cheese websites in your browser.  echo  $(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube  | sudo tee -a /etc/hosts   Stilton  Cheddar  Wensleydale", 
            "title": "Name based routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#path-based-routing", 
            "text": "Now lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.  No problem, we say, why don't we reconfigure the sites to host all 3 under one domain.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheeses-ingress.yaml   Notice that we are configuring Tr\u00e6fik to strip the prefix from the url path\nwith the  traefik.frontend.rule.type  annotation so that we can use\nthe containers from the previous example without modification.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml  echo  $(minikube ip) cheeses.minikube  | sudo tee -a /etc/hosts  You should now be able to visit the websites in your browser.   cheeses.minikube/stilton  cheeses.minikube/cheddar  cheeses.minikube/wensleydale", 
            "title": "Path based routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#specifying-priority-for-routing", 
            "text": "Sometimes you need to specify priority for ingress route, especially when handling wildcard routes.\nThis can be done by adding annotation  traefik.frontend.priority , i.e.:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority: 1\nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority: 2\nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http", 
            "title": "Specifying priority for routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#forwarding-to-externalnames", 
            "text": "When specifying an  ExternalName ,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443.\nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.", 
            "title": "Forwarding to ExternalNames"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-passing-the-host-header", 
            "text": "By default Tr\u00e6fik will pass the incoming Host header on to the upstream resource.\nThere are times however where you may not want this to be the case.\nFor example if your service is of the ExternalName type.", 
            "title": "Disable passing the Host header"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-entirely", 
            "text": "Add the following to your toml config:  disablePassHostHeaders = true", 
            "title": "Disable entirely"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-per-ingress", 
            "text": "To disable passing the Host header per ingress resource set the  traefik.frontend.passHostHeader  annotation on your ingress to  false .  Here is an example ingress definition:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader:  false \nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https  And an example service definition:  apiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com  If you were to visit  example.com/static  the request would then be passed onto  static.otherdomain.com/static  and s tatic.otherdomain.com  would receive the request with the Host header being  static.otherdomain.com .   Note  The per ingress annotation overides whatever the global value is set to.\nSo you could set  disablePassHostHeaders  to  true  in your toml file and then enable passing \nthe host header per ingress if you wanted.", 
            "title": "Disable per ingress"
        }, 
        {
            "location": "/user-guide/kubernetes/#excluding-an-ingress-from-trfik", 
            "text": "You can control which ingress Tr\u00e6fik cares about by using the  kubernetes.io/ingress.class  annotation.\nBy default if the annotation is not set at all Tr\u00e6fik will include the ingress.\nIf the annotation is set to anything other than traefik or a blank string Tr\u00e6fik will ignore it.", 
            "title": "Excluding an ingress from Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/marathon/", 
            "text": "Marathon\n\n\nThis guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.\n\n\nHost detection\n\n\nMarathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being\n\n\n\n\nBRIDGE-networked containers with dynamic high ports exposed\n\n\nHOST-networked containers with host machine ports\n\n\ncontainers with dedicated IP addresses (\nIP-per-task\n).\n\n\n\n\nTraefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the \nforceTaskHostname\n option.\n\n\nGiven the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.\n(Note that this does \nnot\n require rebuilding Traefik but only to point the \nfilename\n configuration parameter to a customized version of the \nmarathon.tmpl\n file on Traefik startup.)\n\n\nPort detection\n\n\nTraefik also attempts to determine the right port (which is a \nnon-trivial matter in Marathon\n).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):\n\n\n\n\nA arbitrary port specified through the \ntraefik.port\n label.\n\n\nThe task port (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nportDefinitions\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nipAddressPerTask\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\n\n\nAchieving high availability\n\n\nScenarios\n\n\nThere are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:\n\n\n\n\nDuring the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.\n\n\nDuring the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.\n\n\nDuring a failure of the application when Traefik has not yet identified the backend as being erroneous.\n\n\n\n\nThe first two scenarios are common with every rolling upgrade of an application (i.e., a new version release or configuration update).\n\n\nThe following sub-sections describe how to resolve or mitigate each scenario.\n\n\nStartup\n\n\nIt is possible to define \nreadiness checks\n (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.\nThe idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range.\nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).\n\n\nBeginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.\nNote that due to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.\n\n\nIf readiness checks are not possible, a current mitigation strategy is to enable \nretries\n and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.\n\n\nShutdown\n\n\nIt is possible to install a \ntermination handler\n (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence\n(i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration).\nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:\n\n\n\n\nDisable Keep-Alive HTTP connections.\n\n\nKeep accepting HTTP requests for a certain period of time.\n\n\nStop accepting new connections.\n\n\nFinish serving any in-flight requests.\n\n\nShut down.\n\n\n\n\nTraefik already ignores Marathon tasks whose state does not match \nTASK_RUNNING\n; since terminating tasks transition into the \nTASK_KILLING\n and eventually \nTASK_KILLED\n state, there is nothing further that needs to be done on Traefik's end.\n\n\nHow long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.\n\n\nAgain, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy.\nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.\n\n\nFailure\n\n\nA failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.\nFailure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.\n\n\nThere are two mitigaton efforts:\n\n\n\n\nConfigure \nMarathon health checks\n on each application.\n\n\nConfigure Traefik health checks (possibly via the \ntraefik.backend.healthcheck.*\n labels) and make sure they probe with proper frequency.\n\n\n\n\nThe Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.\nFor that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.\n\n\n(Non-)Alternatives\n\n\nThere are a few alternatives of varying quality that are frequently asked for. The remaining section is going to explore them along with a benefit/cost trade-off.\n\n\nReusing Marathon health checks\n\n\nIt may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.\n\n\nApart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the \nunknown\n state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure.\nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.\n\n\nFinally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.\n\n\nTraefik used to use the health check results as a strict requirement but moved away from it as \nusers reported the dramatic consequences\n.\nIf health check results are known to exist, however, they will be used to signal task availability.\n\n\nDraining\n\n\nAnother common approach is to let a proxy drain backends that are supposed to shut down. That is, once a backend is supposed to shut down, Traefik would stop forwarding requests.\n\n\nOn the plus side, this would not require any modifications to the application in question. However, implementing this fully within Traefik seems like a non-trivial undertaking.\nAdditionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).\n\n\nThe feature is currently not implemented; a request for draining in general is at \nissue 41\n.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#marathon", 
            "text": "This guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#host-detection", 
            "text": "Marathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being   BRIDGE-networked containers with dynamic high ports exposed  HOST-networked containers with host machine ports  containers with dedicated IP addresses ( IP-per-task ).   Traefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the  forceTaskHostname  option.  Given the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.\n(Note that this does  not  require rebuilding Traefik but only to point the  filename  configuration parameter to a customized version of the  marathon.tmpl  file on Traefik startup.)", 
            "title": "Host detection"
        }, 
        {
            "location": "/user-guide/marathon/#port-detection", 
            "text": "Traefik also attempts to determine the right port (which is a  non-trivial matter in Marathon ).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):   A arbitrary port specified through the  traefik.port  label.  The task port (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  portDefinitions  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  ipAddressPerTask  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).", 
            "title": "Port detection"
        }, 
        {
            "location": "/user-guide/marathon/#achieving-high-availability", 
            "text": "", 
            "title": "Achieving high availability"
        }, 
        {
            "location": "/user-guide/marathon/#scenarios", 
            "text": "There are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:   During the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.  During the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.  During a failure of the application when Traefik has not yet identified the backend as being erroneous.   The first two scenarios are common with every rolling upgrade of an application (i.e., a new version release or configuration update).  The following sub-sections describe how to resolve or mitigate each scenario.", 
            "title": "Scenarios"
        }, 
        {
            "location": "/user-guide/marathon/#startup", 
            "text": "It is possible to define  readiness checks  (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.\nThe idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range.\nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).  Beginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.\nNote that due to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.  If readiness checks are not possible, a current mitigation strategy is to enable  retries  and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.", 
            "title": "Startup"
        }, 
        {
            "location": "/user-guide/marathon/#shutdown", 
            "text": "It is possible to install a  termination handler  (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence\n(i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration).\nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:   Disable Keep-Alive HTTP connections.  Keep accepting HTTP requests for a certain period of time.  Stop accepting new connections.  Finish serving any in-flight requests.  Shut down.   Traefik already ignores Marathon tasks whose state does not match  TASK_RUNNING ; since terminating tasks transition into the  TASK_KILLING  and eventually  TASK_KILLED  state, there is nothing further that needs to be done on Traefik's end.  How long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.  Again, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy.\nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.", 
            "title": "Shutdown"
        }, 
        {
            "location": "/user-guide/marathon/#failure", 
            "text": "A failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.\nFailure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.  There are two mitigaton efforts:   Configure  Marathon health checks  on each application.  Configure Traefik health checks (possibly via the  traefik.backend.healthcheck.*  labels) and make sure they probe with proper frequency.   The Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.\nFor that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.", 
            "title": "Failure"
        }, 
        {
            "location": "/user-guide/marathon/#non-alternatives", 
            "text": "There are a few alternatives of varying quality that are frequently asked for. The remaining section is going to explore them along with a benefit/cost trade-off.", 
            "title": "(Non-)Alternatives"
        }, 
        {
            "location": "/user-guide/marathon/#reusing-marathon-health-checks", 
            "text": "It may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.  Apart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the  unknown  state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure.\nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.  Finally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.  Traefik used to use the health check results as a strict requirement but moved away from it as  users reported the dramatic consequences .\nIf health check results are known to exist, however, they will be used to signal task availability.", 
            "title": "Reusing Marathon health checks"
        }, 
        {
            "location": "/user-guide/marathon/#draining", 
            "text": "Another common approach is to let a proxy drain backends that are supposed to shut down. That is, once a backend is supposed to shut down, Traefik would stop forwarding requests.  On the plus side, this would not require any modifications to the application in question. However, implementing this fully within Traefik seems like a non-trivial undertaking.\nAdditionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).  The feature is currently not implemented; a request for draining in general is at  issue 41 .", 
            "title": "Draining"
        }, 
        {
            "location": "/user-guide/kv-config/", 
            "text": "Key-value store configuration\n\n\nBoth \nstatic global configuration\n and \ndynamic\n configuration can be sorted in a Key-value store.\n\n\nThis section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nStatic configuration in Key-value store\n\n\nWe will see the steps to set it up with an easy example.\nNote that we could do the same with any other Key-value Store.\n\n\ndocker-compose file for Consul\n\n\nThe Tr\u00e6fik global configuration will be getted from a \nConsul\n store.\n\n\nFirst we have to launch Consul in a container.\nThe \ndocker-compose file\n allows us to launch Consul and four instances of the trivial app \nemilevauge/whoamI\n :\n\n\nconsul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    - \n8400:8400\n\n    - \n8500:8500\n\n    - \n8600:53/udp\n\n  expose:\n    - \n8300\n\n    - \n8301\n\n    - \n8301/udp\n\n    - \n8302\n\n    - \n8302/udp\n  \n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami\n\n\n\n\nUpload the configuration in the Key-value store\n\n\nWe should now fill the store with the Tr\u00e6fik global configuration, as we do with a \nTOML file configuration\n.\nTo do that, we can send the Key-value pairs via \ncurl commands\n or via the \nWeb UI\n.\n\n\nFortunately, Tr\u00e6fik allows automation of this process using the \nstoreconfig\n subcommand.\nPlease refer to the \nstore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nHere is the toml configuration we would like to store in the Key-value Store  :\n\n\nlogLevel = \nDEBUG\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \n-----BEGIN CERTIFICATE-----\n                      \ncert file content\n\n                      -----END CERTIFICATE-----\n\n      KeyFile = \n-----BEGIN CERTIFICATE-----\n                      \nkey file content\n\n                      -----END CERTIFICATE-----\n\n\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n[web]\n  address = \n:8081\n\n\n\n\n\nAnd there, the same global configuration in the Key-value Store (using \nprefix = \"traefik\"\n):\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/loglevel\n\n\nDEBUG\n\n\n\n\n\n\n/traefik/defaultentrypoints/0\n\n\nhttp\n\n\n\n\n\n\n/traefik/defaultentrypoints/1\n\n\nhttps\n\n\n\n\n\n\n/traefik/entrypoints/http/address\n\n\n:80\n\n\n\n\n\n\n/traefik/entrypoints/https/address\n\n\n:443\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/certfile\n\n\nintegration/fixtures/https/snitest.com.cert\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/keyfile\n\n\nintegration/fixtures/https/snitest.com.key\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/certfile\n\n\n--BEGIN CERTIFICATE--\ncert file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/keyfile\n\n\n--BEGIN CERTIFICATE--\nkey file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/consul/endpoint\n\n\n127.0.0.1:8500\n\n\n\n\n\n\n/traefik/consul/watch\n\n\ntrue\n\n\n\n\n\n\n/traefik/consul/prefix\n\n\ntraefik\n\n\n\n\n\n\n/traefik/web/address\n\n\n:8081\n\n\n\n\n\n\n\n\nIn case you are setting key values manually:\n- Remember to specify the indexes (\n0\n,\n1\n, \n2\n, ... ) under prefixes \n/traefik/defaultentrypoints/\n and \n/traefik/entrypoints/https/tls/certificates/\n in order to match the global configuration structure.\n- Be careful to give the correct IP address and port on the key \n/traefik/consul/endpoint\n.\n\n\nNote that we can either give path to certificate file or directly the file content itself.\n\n\nLaunch Tr\u00e6fik\n\n\nWe will now launch Tr\u00e6fik in a container.\nWe use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.\n\n\nHere is the \ndocker-compose file\n :\n\n\ntraefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    - \n80:80\n\n    - \n8080:8080\n\n\n\n\n\n\n\nWarning\n\n\nBe careful to give the correct IP address and port in the flag \n--consul.endpoint\n.\n\n\n\n\nConsul ACL Token support\n\n\nTo specify a Consul ACL token for Traefik, we have to set a System Environment variable named \nCONSUL_HTTP_TOKEN\n prior to starting traefik. This variable must be initialized with the ACL token value.\n\n\nIf Traefik is launched into a Docker container, the variable \nCONSUL_HTTP_TOKEN\n can be initialized with the \n-e\n Docker option : \n-e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"\n\n\nTLS support\n\n\nTo connect to a Consul endpoint using SSL, simply specify \nhttps://\n in the \nconsul.endpoint\n property\n\n\n\n\n--consul.endpoint=https://[consul-host]:[consul-ssl-port]\n\n\n\n\nTLS support with client certificates\n\n\nSo far, only \nConsul\n and \netcd\n support TLS connections with client certificates.\nTo set it up, we should enable \nconsul security\n (or \netcd security\n).\n\n\nThen, we have to provide CA, Cert and Key to Tr\u00e6fik using \nconsul\n flags :\n\n\n\n\n--consul.tls\n\n\n--consul.tls.ca=path/to/the/file\n\n\n--consul.tls.cert=path/to/the/file\n\n\n--consul.tls.key=path/to/the/file\n\n\n\n\nOr etcd flags :\n\n\n\n\n--etcd.tls\n\n\n--etcd.tls.ca=path/to/the/file\n\n\n--etcd.tls.cert=path/to/the/file\n\n\n--etcd.tls.key=path/to/the/file\n\n\n\n\nNote that we can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.\n\n\nRemember the command \ntraefik --help\n to display the updated list of flags.\n\n\nDynamic configuration in Key-value store\n\n\nFollowing our example, we will provide backends/frontends rules to Tr\u00e6fik.\n\n\nNote that this section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.\n\n\nKey-value storage structure\n\n\nHere is the toml configuration we would like to store in the store :\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nAnd there, the same dynamic configuration in a KV Store (using \nprefix = \"traefik\"\n):\n\n\n\n\nbackend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend1/circuitbreaker/expression\n\n\nNetworkErrorRatio() \n 0.5\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/tags\n\n\napi,helloworld\n\n\n\n\n\n\n\n\n\n\nbackend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/amount\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/extractorfunc\n\n\nrequest.host\n\n\n\n\n\n\n/traefik/backends/backend2/loadbalancer/method\n\n\ndrr\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/url\n\n\nhttp://172.17.0.5:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/weight\n\n\n2\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/tags\n\n\nweb\n\n\n\n\n\n\n\n\n\n\nfrontend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend1/backend\n\n\nbackend2\n\n\n\n\n\n\n/traefik/frontends/frontend1/routes/test_1/rule\n\n\nHost:test.localhost\n\n\n\n\n\n\n\n\n\n\nfrontend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend2/backend\n\n\nbackend1\n\n\n\n\n\n\n/traefik/frontends/frontend2/passHostHeader\n\n\ntrue\n\n\n\n\n\n\n/traefik/frontends/frontend2/priority\n\n\n10\n\n\n\n\n\n\n/traefik/frontends/frontend2/entrypoints\n\n\nhttp,https\n\n\n\n\n\n\n/traefik/frontends/frontend2/routes/test_2/rule\n\n\nPathPrefix:/test\n\n\n\n\n\n\n\n\nAtomic configuration changes\n\n\nTr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.\n\n\nNote that only backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.\n\n\nThe \nEtcd\n and \nConsul\n backends do not support updating multiple keys atomically. As a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the \n--providersThrottleDuration\n flag. To solve this problem, Tr\u00e6fik supports a special key called \n/traefik/alias\n. If set, Tr\u00e6fik use the value as an alternative key prefix.\n\n\nGiven the key structure below, Tr\u00e6fik will use the \nhttp://172.17.0.2:80\n as its only backend (frontend keys have been omitted for brevity).\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n\n\nWhen an atomic configuration change is required, you may write a new configuration at an alternative prefix. Here, although the \n/traefik_configurations/2/...\n keys have been set, the old configuration is still active because the \n/traefik/alias\n key still points to \n/traefik_configurations/1\n:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nOnce the \n/traefik/alias\n key is updated, the new \n/traefik_configurations/2\n configuration becomes active atomically. Here, we have a 50% balance between the \nhttp://172.17.0.3:80\n and the \nhttp://172.17.0.4:80\n hosts while no traffic is sent to the \n172.17.0.2:80\n host:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/2\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nNote that Tr\u00e6fik \nwill not watch for key changes in the \n/traefik_configurations\n prefix\n. It will only watch for changes in the \n/traefik/alias\n.\nFurther, if the \n/traefik/alias\n key is set, all other configuration with \n/traefik/backends\n or \n/traefik/frontends\n prefix are ignored.\n\n\nStore configuration in Key-value store\n\n\nDon't forget to \nsetup the connection between Tr\u00e6fik and Key-value store\n.\nThe static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the \nstoreconfig\n subcommand\n.\n\n\n$ traefik storeconfig [flags] ...\n\n\n\n\nThis command is here only to automate the \nprocess which upload the configuration into the Key-value store\n.\nTr\u00e6fik will not start but the \nstatic configuration\n will be uploaded into the Key-value store.\nIf you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.\n\n\nTo upload your ACME certificates to the KV store, get your traefik TOML file and add the new \nstorage\n option in the \nacme\n section:\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n # the key where to store your certificates in the KV store\nstorageFile = \nacme.json\n # your old certificates store\n\n\n\n\nCall \ntraefik\u00a0storeconfig\n to upload your config in the KV store.\nThen remove the line \nstorageFile = \"acme.json\"\n from your TOML config file.\n\n\nThat's it!", 
            "title": "Key-value Store Configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-store-configuration", 
            "text": "Both  static global configuration  and  dynamic  configuration can be sorted in a Key-value store.  This section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.  Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb", 
            "title": "Key-value store configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#static-configuration-in-key-value-store", 
            "text": "We will see the steps to set it up with an easy example.\nNote that we could do the same with any other Key-value Store.", 
            "title": "Static configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#docker-compose-file-for-consul", 
            "text": "The Tr\u00e6fik global configuration will be getted from a  Consul  store.  First we have to launch Consul in a container.\nThe  docker-compose file  allows us to launch Consul and four instances of the trivial app  emilevauge/whoamI  :  consul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    -  8400:8400 \n    -  8500:8500 \n    -  8600:53/udp \n  expose:\n    -  8300 \n    -  8301 \n    -  8301/udp \n    -  8302 \n    -  8302/udp   \n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami", 
            "title": "docker-compose file for Consul"
        }, 
        {
            "location": "/user-guide/kv-config/#upload-the-configuration-in-the-key-value-store", 
            "text": "We should now fill the store with the Tr\u00e6fik global configuration, as we do with a  TOML file configuration .\nTo do that, we can send the Key-value pairs via  curl commands  or via the  Web UI .  Fortunately, Tr\u00e6fik allows automation of this process using the  storeconfig  subcommand.\nPlease refer to the  store Tr\u00e6fik configuration  section to get documentation on it.  Here is the toml configuration we would like to store in the Key-value Store  :  logLevel =  DEBUG \n\ndefaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  -----BEGIN CERTIFICATE-----\n                       cert file content \n                      -----END CERTIFICATE----- \n      KeyFile =  -----BEGIN CERTIFICATE-----\n                       key file content \n                      -----END CERTIFICATE----- \n\n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik \n\n[web]\n  address =  :8081   And there, the same global configuration in the Key-value Store (using  prefix = \"traefik\" ):     Key  Value      /traefik/loglevel  DEBUG    /traefik/defaultentrypoints/0  http    /traefik/defaultentrypoints/1  https    /traefik/entrypoints/http/address  :80    /traefik/entrypoints/https/address  :443    /traefik/entrypoints/https/tls/certificates/0/certfile  integration/fixtures/https/snitest.com.cert    /traefik/entrypoints/https/tls/certificates/0/keyfile  integration/fixtures/https/snitest.com.key    /traefik/entrypoints/https/tls/certificates/1/certfile  --BEGIN CERTIFICATE-- cert file content --END CERTIFICATE--    /traefik/entrypoints/https/tls/certificates/1/keyfile  --BEGIN CERTIFICATE-- key file content --END CERTIFICATE--    /traefik/consul/endpoint  127.0.0.1:8500    /traefik/consul/watch  true    /traefik/consul/prefix  traefik    /traefik/web/address  :8081     In case you are setting key values manually:\n- Remember to specify the indexes ( 0 , 1 ,  2 , ... ) under prefixes  /traefik/defaultentrypoints/  and  /traefik/entrypoints/https/tls/certificates/  in order to match the global configuration structure.\n- Be careful to give the correct IP address and port on the key  /traefik/consul/endpoint .  Note that we can either give path to certificate file or directly the file content itself.", 
            "title": "Upload the configuration in the Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#launch-trfik", 
            "text": "We will now launch Tr\u00e6fik in a container.\nWe use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.  Here is the  docker-compose file  :  traefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    -  80:80 \n    -  8080:8080    Warning  Be careful to give the correct IP address and port in the flag  --consul.endpoint .", 
            "title": "Launch Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/kv-config/#consul-acl-token-support", 
            "text": "To specify a Consul ACL token for Traefik, we have to set a System Environment variable named  CONSUL_HTTP_TOKEN  prior to starting traefik. This variable must be initialized with the ACL token value.  If Traefik is launched into a Docker container, the variable  CONSUL_HTTP_TOKEN  can be initialized with the  -e  Docker option :  -e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"", 
            "title": "Consul ACL Token support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support", 
            "text": "To connect to a Consul endpoint using SSL, simply specify  https://  in the  consul.endpoint  property   --consul.endpoint=https://[consul-host]:[consul-ssl-port]", 
            "title": "TLS support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support-with-client-certificates", 
            "text": "So far, only  Consul  and  etcd  support TLS connections with client certificates.\nTo set it up, we should enable  consul security  (or  etcd security ).  Then, we have to provide CA, Cert and Key to Tr\u00e6fik using  consul  flags :   --consul.tls  --consul.tls.ca=path/to/the/file  --consul.tls.cert=path/to/the/file  --consul.tls.key=path/to/the/file   Or etcd flags :   --etcd.tls  --etcd.tls.ca=path/to/the/file  --etcd.tls.cert=path/to/the/file  --etcd.tls.key=path/to/the/file   Note that we can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.  Remember the command  traefik --help  to display the updated list of flags.", 
            "title": "TLS support with client certificates"
        }, 
        {
            "location": "/user-guide/kv-config/#dynamic-configuration-in-key-value-store", 
            "text": "Following our example, we will provide backends/frontends rules to Tr\u00e6fik.  Note that this section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.", 
            "title": "Dynamic configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-storage-structure", 
            "text": "Here is the toml configuration we would like to store in the store :  [file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test   And there, the same dynamic configuration in a KV Store (using  prefix = \"traefik\" ):   backend 1      Key  Value      /traefik/backends/backend1/circuitbreaker/expression  NetworkErrorRatio()   0.5    /traefik/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik/backends/backend1/servers/server1/weight  10    /traefik/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik/backends/backend1/servers/server2/weight  1    /traefik/backends/backend1/servers/server2/tags  api,helloworld      backend 2      Key  Value      /traefik/backends/backend2/maxconn/amount  10    /traefik/backends/backend2/maxconn/extractorfunc  request.host    /traefik/backends/backend2/loadbalancer/method  drr    /traefik/backends/backend2/servers/server1/url  http://172.17.0.4:80    /traefik/backends/backend2/servers/server1/weight  1    /traefik/backends/backend2/servers/server2/url  http://172.17.0.5:80    /traefik/backends/backend2/servers/server2/weight  2    /traefik/backends/backend2/servers/server2/tags  web      frontend 1      Key  Value      /traefik/frontends/frontend1/backend  backend2    /traefik/frontends/frontend1/routes/test_1/rule  Host:test.localhost      frontend 2      Key  Value      /traefik/frontends/frontend2/backend  backend1    /traefik/frontends/frontend2/passHostHeader  true    /traefik/frontends/frontend2/priority  10    /traefik/frontends/frontend2/entrypoints  http,https    /traefik/frontends/frontend2/routes/test_2/rule  PathPrefix:/test", 
            "title": "Key-value storage structure"
        }, 
        {
            "location": "/user-guide/kv-config/#atomic-configuration-changes", 
            "text": "Tr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.  Note that only backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.  The  Etcd  and  Consul  backends do not support updating multiple keys atomically. As a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the  --providersThrottleDuration  flag. To solve this problem, Tr\u00e6fik supports a special key called  /traefik/alias . If set, Tr\u00e6fik use the value as an alternative key prefix.  Given the key structure below, Tr\u00e6fik will use the  http://172.17.0.2:80  as its only backend (frontend keys have been omitted for brevity).     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10     When an atomic configuration change is required, you may write a new configuration at an alternative prefix. Here, although the  /traefik_configurations/2/...  keys have been set, the old configuration is still active because the  /traefik/alias  key still points to  /traefik_configurations/1 :     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Once the  /traefik/alias  key is updated, the new  /traefik_configurations/2  configuration becomes active atomically. Here, we have a 50% balance between the  http://172.17.0.3:80  and the  http://172.17.0.4:80  hosts while no traffic is sent to the  172.17.0.2:80  host:     Key  Value      /traefik/alias  /traefik_configurations/2    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.4:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Note that Tr\u00e6fik  will not watch for key changes in the  /traefik_configurations  prefix . It will only watch for changes in the  /traefik/alias .\nFurther, if the  /traefik/alias  key is set, all other configuration with  /traefik/backends  or  /traefik/frontends  prefix are ignored.", 
            "title": "Atomic configuration changes"
        }, 
        {
            "location": "/user-guide/kv-config/#store-configuration-in-key-value-store", 
            "text": "Don't forget to  setup the connection between Tr\u00e6fik and Key-value store .\nThe static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the  storeconfig  subcommand .  $ traefik storeconfig [flags] ...  This command is here only to automate the  process which upload the configuration into the Key-value store .\nTr\u00e6fik will not start but the  static configuration  will be uploaded into the Key-value store.\nIf you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.  To upload your ACME certificates to the KV store, get your traefik TOML file and add the new  storage  option in the  acme  section:  [acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account  # the key where to store your certificates in the KV store\nstorageFile =  acme.json  # your old certificates store  Call  traefik\u00a0storeconfig  to upload your config in the KV store.\nThen remove the line  storageFile = \"acme.json\"  from your TOML config file.  That's it!", 
            "title": "Store configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/cluster/", 
            "text": "Clustering / High Availability (beta)\n\n\nThis guide explains how tu use Tr\u00e6fik in high availability mode.\nIn order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.\n\n\nPrerequisites\n\n\nYou will need a working KV store cluster.\n\n\nFile configuration to KV store migration\n\n\nWe created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.\nPlease refer to \nthis section\n to get more details.\n\n\nDeploy a Tr\u00e6fik cluster\n\n\nOnce your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.\nA Tr\u00e6fik cluster is based on a manager/worker model.\nWhen starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.", 
            "title": "Clustering/HA"
        }, 
        {
            "location": "/user-guide/cluster/#clustering-high-availability-beta", 
            "text": "This guide explains how tu use Tr\u00e6fik in high availability mode.\nIn order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.", 
            "title": "Clustering / High Availability (beta)"
        }, 
        {
            "location": "/user-guide/cluster/#prerequisites", 
            "text": "You will need a working KV store cluster.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/cluster/#file-configuration-to-kv-store-migration", 
            "text": "We created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.\nPlease refer to  this section  to get more details.", 
            "title": "File configuration to KV store migration"
        }, 
        {
            "location": "/user-guide/cluster/#deploy-a-trfik-cluster", 
            "text": "Once your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.\nA Tr\u00e6fik cluster is based on a manager/worker model.\nWhen starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.", 
            "title": "Deploy a Tr\u00e6fik cluster"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/", 
            "text": "Docker \n Traefik\n\n\nIn this use case, we want to use Traefik as a \nlayer-7\n load balancer with SSL termination for a set of micro-services used to run a web application.\nWe also want to automatically \ndiscover any services\n on the Docker host and let Traefik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.\nIn addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.\n\n\nSetting Up\n\n\nIn order for this to work, you'll need a server with a public IP address, with Docker installed on it.\nIn this example, we're using the fictitious domain \nmy-awesome-app.org\n.\nIn real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.\n\n\nNetworking\n\n\nDocker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers \nunless you'd want to\n.\nIn this example, we're going to use a single network called \nweb\n where all containers that are handling HTTP traffic (including Traefik) will reside in.\n\n\nOn the Docker host, run the following command:\n\n\n$ docker network create web\n\n\nNow, let's create a directory on the server where we will configure the rest of Traefik:\n\n\n$ mkdir -p /opt/traefik\n\n\nWithin this directory, we're going to create 3 empty files:\n\n\n$ touch /opt/traefik/docker-compose.yml\n$ touch /opt/traefik/acme.json \n chmod 600 /opt/traefik/acme.json\n$ touch /opt/traefik/traefik.toml\n\n\n\n\nThe \ndocker-compose.yml\n file will provide us with a simple, consistent and more importantly, a deterministic way to create Traefik.\nThe contents of the file is as follows:\n\n\nversion: '2'\n\nservices:\n  traefik:\n    image: traefik:1.3.5\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /srv/traefik/traefik.toml:/traefik.toml\n      - /srv/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nAs you can see, we're mounting the \ntraefik.toml\n file as well as the (empty) \nacme.json\n file in the container.\nAlso, we're mounting the \n/var/run/docker.sock\n Docker socket in the container as well, so Traefik can listen to Docker events and reconfigure it's own internal configuration when containers are created (or shut down).\nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports \n80\n and \n443\n on the host, and making sure the container is placed within the \nweb\n network we've created earlier on.\nFinally, we're giving this container a static name called \ntraefik\n.\n\n\nLet's take a look at a simply \ntraefik.toml\n configuration as well before we'll create the Traefik container:\n\n\ndebug = false\ncheckNewVersion = true\nlogLevel = \nERROR\n\ndefaultEntryPoints = [\nhttps\n,\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint = \nunix:///var/run/docker.sock\n\ndomain = \nmy-awesome-app.org\n\nwatch = true\nexposedbydefault = false\n\n[acme]\nemail = \nyour-email-here@my-awesome-app.org\n\nstorage = \nacme.json\n\nentryPoint = \nhttps\n\nOnHostRule = true\n\n\n\n\nThis is the minimum configuration required to do the following:\n\n\n\n\nLog \nERROR\n-level messages (or more severe) to the console, but silence \nDEBUG\n-level messagse\n\n\nCheck for new versions of Traefik periodically\n\n\nCreate two entry points, namely an \nHTTP\n endpoint on port \n80\n, and an \nHTTPS\n endpoint on port \n443\n where all incoming traffic on port \n80\n will immediately get redirected to \nHTTPS\n.\n\n\nEnable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However, \nnew containers will not be exposed by Traefik by default, we'll get into this in a bit!\n\n\nEnable automatic request and configuration of SSL certificates using Let's Encrypt. These certificates will be stored in the \nacme.json\n file, which you can back-up yourself and store off-premises.\n\n\n\n\nAlright, let's boot the container. From the \n/opt/traefik\n directory, run \n$ docker-compose up -d\n which will create and start the Traefik container.\n\n\nExposing Web Services to the Outside World\n\n\nNow that we've fully configured and started Traefik, it's time to get our applications running!\n\n\nLet's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not. The \ndocker-compose.yml\n of our project looks like this:\n\n\nversion: \n2.1\n\n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n9000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-app\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=9000\n\n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n3000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-events\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:events.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=3000\n\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nHere, we can see a set of services with two applications that we're actually exposing to the outside world.\nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks.\nAlso, only the containers that we want traffic to get routed to are attached to the \nweb\n network we created at the start of this document.\nSince the \ntraefik\n container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.\n\n\nLabels\n\n\nAs mentioned earlier, we don't want containers exposed automatically by Traefik.\nThe reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Traefik how to create it's internal routing configuration.\nLet's take a look at the labels themselves for the \napp\n service, which is a HTTP webservice listing on port 9000:\n\n\n- \ntraefik.backend=my-awesome-app-app\n\n- \ntraefik.docker.network=web\n\n- \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n- \ntraefik.enable=true\n\n- \ntraefik.port=9000\n\n\n\n\n\nFirst, we specify the \nbackend\n name which corresponds to the actual service we're routing \nto\n.\nWe also tell Traefik to use the \nweb\n network to route HTTP traffic to this container. With the \nfrontend.rule\n label, we tell Traefik that we want to route to this container if the incoming HTTP request contains the \nHost\n \napp.my-awesome-app.org\n.\nEssentially, this is the actual rule used for Layer-7 load balancing.\nWith the \ntraefik.enable\n label, we tell Traefik to include this container in it's internal configuration.\nFinally but not unimportantly, we tell Traefik to route \nto\n port \n9000\n, since that is the actual TCP/IP port the container actually listens on.\n\n\nGotchas and tips\n\n\n\n\nAlways specify the correct port where the container expects HTTP traffic using \ntraefik.port\n label.\n    If a container exposes multiple ports, Traefik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.\n\n\nShould you choose to enable the \nexposedbydefault\n flag in the \ntraefik.toml\n configuration, be aware that all containers that are placed in the same network as Traefik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.\n\n\nWith the \ntraefik.frontend.auth.basic\n label, it's possible for Traefik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.\n\n\nTraefik has built-in support to automatically export \nPrometheus\n metrics\n\n\nTraefik supports websockets out of the box. In the example above, the \nevents\n-service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)\n\n\n\n\nFinal thoughts\n\n\nUsing Traefik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, performant and self-configuring solution for your projects.\nWith Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Getting Started with Docker & Lets Encrypt"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#docker-traefik", 
            "text": "In this use case, we want to use Traefik as a  layer-7  load balancer with SSL termination for a set of micro-services used to run a web application.\nWe also want to automatically  discover any services  on the Docker host and let Traefik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.\nIn addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.", 
            "title": "Docker &amp; Traefik"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#setting-up", 
            "text": "In order for this to work, you'll need a server with a public IP address, with Docker installed on it.\nIn this example, we're using the fictitious domain  my-awesome-app.org .\nIn real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.", 
            "title": "Setting Up"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#networking", 
            "text": "Docker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers  unless you'd want to .\nIn this example, we're going to use a single network called  web  where all containers that are handling HTTP traffic (including Traefik) will reside in.  On the Docker host, run the following command:  $ docker network create web  Now, let's create a directory on the server where we will configure the rest of Traefik:  $ mkdir -p /opt/traefik  Within this directory, we're going to create 3 empty files:  $ touch /opt/traefik/docker-compose.yml\n$ touch /opt/traefik/acme.json   chmod 600 /opt/traefik/acme.json\n$ touch /opt/traefik/traefik.toml  The  docker-compose.yml  file will provide us with a simple, consistent and more importantly, a deterministic way to create Traefik.\nThe contents of the file is as follows:  version: '2'\n\nservices:\n  traefik:\n    image: traefik:1.3.5\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /srv/traefik/traefik.toml:/traefik.toml\n      - /srv/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true  As you can see, we're mounting the  traefik.toml  file as well as the (empty)  acme.json  file in the container.\nAlso, we're mounting the  /var/run/docker.sock  Docker socket in the container as well, so Traefik can listen to Docker events and reconfigure it's own internal configuration when containers are created (or shut down).\nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports  80  and  443  on the host, and making sure the container is placed within the  web  network we've created earlier on.\nFinally, we're giving this container a static name called  traefik .  Let's take a look at a simply  traefik.toml  configuration as well before we'll create the Traefik container:  debug = false\ncheckNewVersion = true\nlogLevel =  ERROR \ndefaultEntryPoints = [ https , http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint =  unix:///var/run/docker.sock \ndomain =  my-awesome-app.org \nwatch = true\nexposedbydefault = false\n\n[acme]\nemail =  your-email-here@my-awesome-app.org \nstorage =  acme.json \nentryPoint =  https \nOnHostRule = true  This is the minimum configuration required to do the following:   Log  ERROR -level messages (or more severe) to the console, but silence  DEBUG -level messagse  Check for new versions of Traefik periodically  Create two entry points, namely an  HTTP  endpoint on port  80 , and an  HTTPS  endpoint on port  443  where all incoming traffic on port  80  will immediately get redirected to  HTTPS .  Enable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However,  new containers will not be exposed by Traefik by default, we'll get into this in a bit!  Enable automatic request and configuration of SSL certificates using Let's Encrypt. These certificates will be stored in the  acme.json  file, which you can back-up yourself and store off-premises.   Alright, let's boot the container. From the  /opt/traefik  directory, run  $ docker-compose up -d  which will create and start the Traefik container.", 
            "title": "Networking"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#exposing-web-services-to-the-outside-world", 
            "text": "Now that we've fully configured and started Traefik, it's time to get our applications running!  Let's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not. The  docker-compose.yml  of our project looks like this:  version:  2.1 \n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  9000 \n    labels:\n      -  traefik.backend=my-awesome-app-app \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:app.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=9000 \n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  3000 \n    labels:\n      -  traefik.backend=my-awesome-app-events \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:events.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=3000 \n\nnetworks:\n  web:\n    external: true  Here, we can see a set of services with two applications that we're actually exposing to the outside world.\nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks.\nAlso, only the containers that we want traffic to get routed to are attached to the  web  network we created at the start of this document.\nSince the  traefik  container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.", 
            "title": "Exposing Web Services to the Outside World"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#labels", 
            "text": "As mentioned earlier, we don't want containers exposed automatically by Traefik.\nThe reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Traefik how to create it's internal routing configuration.\nLet's take a look at the labels themselves for the  app  service, which is a HTTP webservice listing on port 9000:  -  traefik.backend=my-awesome-app-app \n-  traefik.docker.network=web \n-  traefik.frontend.rule=Host:app.my-awesome-app.org \n-  traefik.enable=true \n-  traefik.port=9000   First, we specify the  backend  name which corresponds to the actual service we're routing  to .\nWe also tell Traefik to use the  web  network to route HTTP traffic to this container. With the  frontend.rule  label, we tell Traefik that we want to route to this container if the incoming HTTP request contains the  Host   app.my-awesome-app.org .\nEssentially, this is the actual rule used for Layer-7 load balancing.\nWith the  traefik.enable  label, we tell Traefik to include this container in it's internal configuration.\nFinally but not unimportantly, we tell Traefik to route  to  port  9000 , since that is the actual TCP/IP port the container actually listens on.", 
            "title": "Labels"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#gotchas-and-tips", 
            "text": "Always specify the correct port where the container expects HTTP traffic using  traefik.port  label.\n    If a container exposes multiple ports, Traefik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.  Should you choose to enable the  exposedbydefault  flag in the  traefik.toml  configuration, be aware that all containers that are placed in the same network as Traefik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.  With the  traefik.frontend.auth.basic  label, it's possible for Traefik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.  Traefik has built-in support to automatically export  Prometheus  metrics  Traefik supports websockets out of the box. In the example above, the  events -service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)", 
            "title": "Gotchas and tips"
        }, 
        {
            "location": "/user-guide/getting-started-with-docker-and-lets-encrypt/#final-thoughts", 
            "text": "Using Traefik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, performant and self-configuring solution for your projects.\nWith Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Final thoughts"
        }, 
        {
            "location": "/benchmarks/", 
            "text": "Benchmarks\n\n\nConfiguration\n\n\nI would like to thanks \nvincentbernat\n from \nexoscale.ch\n who kindly provided the infrastructure needed for the benchmarks.\n\n\nI used 4 VMs for the tests with the following configuration:\n\n\n\n\n32 GB RAM\n\n\n8 CPU Cores\n\n\n10 GB SSD\n\n\nUbuntu 14.04 LTS 64-bit\n\n\n\n\nSetup\n\n\n\n\nOne VM used to launch the benchmarking tool \nwrk\n\n\nOne VM for traefik (v1.0.0-beta.416) / nginx (v1.4.6)\n\n\nTwo VMs for 2 backend servers in go \nwhoami\n\n\n\n\nEach VM has been tuned using the following limits:\n\n\nsysctl -w fs.file-max=\n9999999\n\nsysctl -w fs.nr_open=\n9999999\n\nsysctl -w net.core.netdev_max_backlog=\n4096\n\nsysctl -w net.core.rmem_max=\n16777216\n\nsysctl -w net.core.somaxconn=\n65535\n\nsysctl -w net.core.wmem_max=\n16777216\n\nsysctl -w net.ipv4.ip_local_port_range=\n1025       65535\n\nsysctl -w net.ipv4.tcp_fin_timeout=\n30\n\nsysctl -w net.ipv4.tcp_keepalive_time=\n30\n\nsysctl -w net.ipv4.tcp_max_syn_backlog=\n20480\n\nsysctl -w net.ipv4.tcp_max_tw_buckets=\n400000\n\nsysctl -w net.ipv4.tcp_no_metrics_save=\n1\n\nsysctl -w net.ipv4.tcp_syn_retries=\n2\n\nsysctl -w net.ipv4.tcp_synack_retries=\n2\n\nsysctl -w net.ipv4.tcp_tw_recycle=\n1\n\nsysctl -w net.ipv4.tcp_tw_reuse=\n1\n\nsysctl -w vm.min_free_kbytes=\n65536\n\nsysctl -w vm.overcommit_memory=\n1\n\nulimit -n 9999999\n\n\n\n\nNginx\n\n\nHere is the config Nginx file use \n/etc/nginx/nginx.conf\n:\n\n\nuser www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s; \n    open_file_cache_valid 300s; \n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}\n\n\n\n\nHere is the Nginx vhost file used:\n\n\nupstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host != \ntest.traefik\n) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \n;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}\n\n\n\n\nTraefik\n\n\nHere is the \ntraefik.toml\n file used:\n\n\nMaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:8000\n\n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url = \nhttp://IP-whoami1:80\n\n    weight = 1\n    [backends.backend1.servers.server2]\n    url = \nhttp://IP-whoami2:80\n\n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost: test.traefik\n\n\n\n\n\nResults\n\n\nwhoami:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB\n\n\n\n\nnginx:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB\n\n\n\n\ntraefik:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB\n\n\n\n\nConclusion\n\n\nTraefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !\n\n\nSome areas of possible improvements:\n\n\n\n\nUse \nGO_REUSEPORT\n listener\n\n\nRun a separate server instance per CPU core with \nGOMAXPROCS=1\n (it appears during benchmarks that there is a lot more context switches with traefik than with nginx)", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#benchmarks", 
            "text": "", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#configuration", 
            "text": "I would like to thanks  vincentbernat  from  exoscale.ch  who kindly provided the infrastructure needed for the benchmarks.  I used 4 VMs for the tests with the following configuration:   32 GB RAM  8 CPU Cores  10 GB SSD  Ubuntu 14.04 LTS 64-bit", 
            "title": "Configuration"
        }, 
        {
            "location": "/benchmarks/#setup", 
            "text": "One VM used to launch the benchmarking tool  wrk  One VM for traefik (v1.0.0-beta.416) / nginx (v1.4.6)  Two VMs for 2 backend servers in go  whoami   Each VM has been tuned using the following limits:  sysctl -w fs.file-max= 9999999 \nsysctl -w fs.nr_open= 9999999 \nsysctl -w net.core.netdev_max_backlog= 4096 \nsysctl -w net.core.rmem_max= 16777216 \nsysctl -w net.core.somaxconn= 65535 \nsysctl -w net.core.wmem_max= 16777216 \nsysctl -w net.ipv4.ip_local_port_range= 1025       65535 \nsysctl -w net.ipv4.tcp_fin_timeout= 30 \nsysctl -w net.ipv4.tcp_keepalive_time= 30 \nsysctl -w net.ipv4.tcp_max_syn_backlog= 20480 \nsysctl -w net.ipv4.tcp_max_tw_buckets= 400000 \nsysctl -w net.ipv4.tcp_no_metrics_save= 1 \nsysctl -w net.ipv4.tcp_syn_retries= 2 \nsysctl -w net.ipv4.tcp_synack_retries= 2 \nsysctl -w net.ipv4.tcp_tw_recycle= 1 \nsysctl -w net.ipv4.tcp_tw_reuse= 1 \nsysctl -w vm.min_free_kbytes= 65536 \nsysctl -w vm.overcommit_memory= 1 \nulimit -n 9999999", 
            "title": "Setup"
        }, 
        {
            "location": "/benchmarks/#nginx", 
            "text": "Here is the config Nginx file use  /etc/nginx/nginx.conf :  user www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s; \n    open_file_cache_valid 300s; \n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}  Here is the Nginx vhost file used:  upstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host !=  test.traefik ) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection  ;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}", 
            "title": "Nginx"
        }, 
        {
            "location": "/benchmarks/#traefik", 
            "text": "Here is the  traefik.toml  file used:  MaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :8000 \n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url =  http://IP-whoami1:80 \n    weight = 1\n    [backends.backend1.servers.server2]\n    url =  http://IP-whoami2:80 \n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host: test.traefik", 
            "title": "Traefik"
        }, 
        {
            "location": "/benchmarks/#results", 
            "text": "", 
            "title": "Results"
        }, 
        {
            "location": "/benchmarks/#whoami", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB", 
            "title": "whoami:"
        }, 
        {
            "location": "/benchmarks/#nginx_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB", 
            "title": "nginx:"
        }, 
        {
            "location": "/benchmarks/#traefik_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB", 
            "title": "traefik:"
        }, 
        {
            "location": "/benchmarks/#conclusion", 
            "text": "Traefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !  Some areas of possible improvements:   Use  GO_REUSEPORT  listener  Run a separate server instance per CPU core with  GOMAXPROCS=1  (it appears during benchmarks that there is a lot more context switches with traefik than with nginx)", 
            "title": "Conclusion"
        }
    ]
}